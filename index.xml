<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ge[o]rges Dib</title>
    <link>https://dibgerge.github.io/</link>
      <atom:link href="https://dibgerge.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Ge[o]rges Dib</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 11 Mar 2019 00:00:00 -0700</lastBuildDate>
    <image>
      <url>https://dibgerge.github.io/images/icon_hufb0bba0b24038dd6774d907c032416d0_44829_512x512_fill_lanczos_center_2.png</url>
      <title>Ge[o]rges Dib</title>
      <link>https://dibgerge.github.io/</link>
    </image>
    
    <item>
      <title>Tensorflow, PyTorch, and MxNet</title>
      <link>https://dibgerge.github.io/post/tf-mxnet-pytorch/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/post/tf-mxnet-pytorch/</guid>
      <description>&lt;p&gt;In the past 2 years, I have been exclusively using Tensorflow with Keras for training and testing deep neural networks. I never really thought twice about it, because this is what everyone else seems to be using. I mean, just looking at the popularity of those frameworks in github compared with their closest competitors was enough to make the decision for me. Here are the approximate statistics as of March 2019 for the four most popular frameworks.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;
&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tensorflow&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;
&lt;a href=&#34;https://github.com/keras-team/keras&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Keras&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;
&lt;a href=&#34;https://github.com/pytorch/pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pytorch&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;
&lt;a href=&#34;https://github.com/apache/incubator-mxnet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mxnet&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Github &lt;i class=&#34;fas fa-star&#34;&gt;&lt;/i&gt;&lt;/td&gt;
&lt;td&gt;122,500&lt;/td&gt;
&lt;td&gt;39,000&lt;/td&gt;
&lt;td&gt;25,500&lt;/td&gt;
&lt;td&gt;16,500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Recently, I have been going through the lectures of 
&lt;a href=&#34;fast.ai&#34;&gt;Jeremy Howard&amp;rsquo;s Fast.ai&lt;/a&gt; excellent class, where they use Pytorch as the backend of the high-level library they built. This was one of the reasons I started questioning what was I missing by limiting myself to Tensorflow. Also, I have seen the extensive vision library of 
&lt;a href=&#34;https://gluon-cv.mxnet.io/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MxNet&amp;rsquo;s GluonCV&lt;/a&gt;, and this really made me feel that I might be missing out.&lt;/p&gt;
&lt;p&gt;In addition to all the fear of missing out stuff, I was coding my own implementation of 
&lt;a href=&#34;https://gluon-cv.mxnet.io/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ResNet&lt;/a&gt;, and I scoured online the plethora of different implementations of ResNet, some with lots of &lt;i class=&#34;fas fa-star&#34;&gt;s&lt;/i&gt;. I realized that many had implementation details which differed from the original paper, and it was not clear if it is intentional or not. Thus I really though that a test in reproducibility is due and so I did.&lt;/p&gt;
&lt;p&gt;I set out to compare the three frameworks: tensorflow, pytorch, and mxnet. I wanted to use some of the built-in convolutional neural networks with built-in pre-trained weights to directly classify Imagenet&amp;rsquo;s validation dataset images. Throughout this comparison, I was looking for three factors:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ease of loading the dataset and reproducing the pre-processing steps required before feeding images to the neural network for classification.&lt;/li&gt;
&lt;li&gt;Computed error rate vs framework&amp;rsquo;s reported error. It would be also nice to compare the results with the original publication, but most report validation error using 10-crops, and here we use only single crop.&lt;/li&gt;
&lt;li&gt;Inference speed.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;dataset-and-convolutional-neural-network-architectures&#34;&gt;Dataset and Convolutional Neural Network Architectures&lt;/h2&gt;
&lt;p&gt;The datatset I used was Imagenet&amp;rsquo;s validation dataset which constitutes of 50,000 images with different sizes. The easiest way to get your hands on the data is to download it from Kaggle 
&lt;a href=&#34;https://www.kaggle.com/c/imagenet-object-localization-challenge&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the frameworks, I used the following versions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tensorflow 1.13&lt;/strong&gt; with Keras as the front-end interface (Note this is different from using Keras with Tensorflow backend since now Tensorflow comes packed with its own Keras version, which is not compatible with other frameworks).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyTorch 1.0.1&lt;/strong&gt; with PyTorch vision for convolutional neural networks implementations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MxNet 1.4&lt;/strong&gt; with GluonCV for convolutional neural networks implementaitons&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the convolutional neural network, I considered four different architectures: 
&lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ResNet50&lt;/a&gt;, 
&lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Resnet101&lt;/a&gt;, 
&lt;a href=&#34;https://arxiv.org/abs/1704.04861&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mobilenet&lt;/a&gt;, and 
&lt;a href=&#34;https://arxiv.org/abs/1608.06993&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Densenet121&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The top 1 error published on each frameworks&amp;rsquo; website, based on a single center crop evaluation is as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;
&lt;a href=&#34;https://github.com/keras-team/keras-applications&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tensorflow (Keras)&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;
&lt;a href=&#34;https://pytorch.org/docs/stable/torchvision/models.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pytorch&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;
&lt;a href=&#34;https://gluon-cv.mxnet.io/model_zoo/classification.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mxnet (GluonCV)&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;25.10&lt;/td&gt;
&lt;td&gt;23.85&lt;/td&gt;
&lt;td&gt;22.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;23.60&lt;/td&gt;
&lt;td&gt;22.63&lt;/td&gt;
&lt;td&gt;21.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;29.60&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;26.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;25.0&lt;/td&gt;
&lt;td&gt;25.35&lt;/td&gt;
&lt;td&gt;25.03&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We note here that the error for Resnet101 is reported in Keras Applications, but Resnet101 is not packaged with Tensorflow 1.13, which is used in this experiment, and thus we won&amp;rsquo;t have any results for it. Also, Pytorch does not come packaged with an implementation of Mobilenet.&lt;/p&gt;
&lt;p&gt;Also, it is interesting to see that especially for Resnet implementations, it is obvious that the accuracy of Mxnet &amp;gt; PyTorch &amp;gt; Tensorflow.&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;All the code used here can be found on 
&lt;a href=&#34;https://github.com/dibgerge/blog-tf-mxnet-pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt;. The biggest challenge here really is loading and pre-processing the images the right way. The following briefly describes how I did it for each of the three frameworks.&lt;/p&gt;
&lt;h3 id=&#34;tensorflow-pre-processing&#34;&gt;Tensorflow pre-processing&lt;/h3&gt;
&lt;p&gt;Uses the &lt;code&gt;Sequence&lt;/code&gt; abstract class for loading the data using a a generator. The pre-processing pipeline is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Resized the shorter side of the image to 256 pixels (implemented manually).&lt;/li&gt;
&lt;li&gt;Center cropped the image to 224 x 224 pixels (implemented manually).&lt;/li&gt;
&lt;li&gt;Apply the function &lt;code&gt;preprocess_input&lt;/code&gt; which applies the appropriate normalization based on how the network is trained. This function is provided with each different architecture built-in Tensorflow&amp;rsquo;s Keras frontend.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;pytorch-pre-processing&#34;&gt;Pytorch pre-processing&lt;/h3&gt;
&lt;p&gt;Used the &lt;code&gt;Dataset&lt;/code&gt; and &lt;code&gt;Dataloader&lt;/code&gt; interfaces to feed the data to the neural network. The standard pipeline for pre-processing images for all architectures is documented and is a composition of four transforms using Pytorch&amp;rsquo;s &lt;code&gt;transforms&lt;/code&gt; API:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Resize image to 256 pixels (using &lt;code&gt;transforms.Resize&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Center image to 224 pixels (using &lt;code&gt;transforms.CenterCrop&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Convert images to pytorch tensor (using &lt;code&gt;transforms.ToTensor&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Normalize image by mean subtraction and standard deviation scaling (using &lt;code&gt;transforms.Normalize&lt;/code&gt;). The normalization values are given in the Pytorch&amp;rsquo;s documentation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;mxnet-pre-processing&#34;&gt;Mxnet pre-processing&lt;/h3&gt;
&lt;p&gt;Used the &lt;code&gt;Dataset&lt;/code&gt; and &lt;code&gt;Dataloader&lt;/code&gt; interfaces to feed the data to the neural network. Mxnet comes packaged with a preset function which applies the required pipeline for models pre-trained on imagenet, using the &lt;code&gt;gluoncv.data.transforms.presets.imagenet.transform_eval&lt;/code&gt; function.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;The following table summarizes the achieved error percentages for each of the four architectures using the three different frameworks.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;(% error)&lt;/th&gt;
&lt;th&gt;Tensorflow&lt;/th&gt;
&lt;th&gt;Pytorch&lt;/th&gt;
&lt;th&gt;Mxnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;26.92&lt;/td&gt;
&lt;td&gt;23.87&lt;/td&gt;
&lt;td&gt;22.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;22.63&lt;/td&gt;
&lt;td&gt;21.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;29.91&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;26.73&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;26.69&lt;/td&gt;
&lt;td&gt;25.57&lt;/td&gt;
&lt;td&gt;25.10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Interestingly, although I had the most experience with Keras, I could not reproduce the published results for Resnet and Densenet. This is probably because I had to manually implement the image resizing and cropping, which might be different one used to generate the published results. On the other hand, Pytorch provides the required documentation to be able to reproduce the results very closely. MxNet takes it even a step further by providing a single function which applies all required pre-processing, and the results match very well with published ones.&lt;/p&gt;
&lt;p&gt;As for running times, I measured the total running time for classifying 50,000 images.  All predictions were made on GPU (Nvidia GTX 1080 Ti), while the image pre-processing was made on CPU. The following tables summarizes the running time results in seconds. &lt;strong&gt;Please take those results with a huge grain of salt, since times vary a lot when loading and reloading large data from disk&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;(seconds)&lt;/th&gt;
&lt;th&gt;Tensorflow&lt;/th&gt;
&lt;th&gt;Pytorch&lt;/th&gt;
&lt;th&gt;Mxnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;137&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;140&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;159&lt;/td&gt;
&lt;td&gt;214&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;82&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;118&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;173&lt;/td&gt;
&lt;td&gt;120&lt;/td&gt;
&lt;td&gt;195&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;First, those results are somehow unfair to tensorflow. This is because I used threading with 4 workers for pre-processing images in Tensorflow, while 4 workers with multiprocessing was used for MxNet and Pytorch. But, this is rather Tensorflow/keras fault due to a 
&lt;a href=&#34;https://github.com/keras-team/keras/issues/10855&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bug&lt;/a&gt; not allowing me to use multiprocessing. Also, for Mxnet and Pytorch I measured the average time it took to classify 10 images (the batch size used). I did not do this in Tensorflow, because there is no easy way to measure per-batch times.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;(milliseconds)&lt;/th&gt;
&lt;th&gt;Tensorflow*&lt;/th&gt;
&lt;th&gt;Pytorch&lt;/th&gt;
&lt;th&gt;Mxnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;6.7 $\pm$ 4.3&lt;/td&gt;
&lt;td&gt;12.1 $\pm$ 1.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;11.8 $\pm$ 1.2&lt;/td&gt;
&lt;td&gt;21.0 $\pm$ 3.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;6.7 $\pm$ 1.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;15.6 $\pm$ 1.7&lt;/td&gt;
&lt;td&gt;26.7 $\pm$ 3.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Most of the time here is being spent loading the data from disk, and the GPU is not fully utilized. For example, based on average inference of 10 images in Resnet50, it takes about 33.5 seconds to classify all 50,000 images using PyTorch and about 60.5 seconds using Mxnet. We can reduce total inference by more than half if the GPU is kept busy.
Thus, the importance of handling data appropriately if speed matters.&lt;/p&gt;
&lt;h2 id=&#34;who-is-the-winner&#34;&gt;Who is the winner?&lt;/h2&gt;
&lt;p&gt;I think this experiment allowed me to assess three things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Availability of pre-trained networks&lt;/strong&gt;: trophy goes to &lt;em&gt;Mxnet&lt;/em&gt;. The extensive vision library of architectures/preset image processing is very impressive. Jury still out on other domains (RL, NLP). Tensorflow is a second, and Pytorch did not have much architecture packaged with it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reproducibility&lt;/strong&gt;: Again, trophy to &lt;em&gt;Mxnet&lt;/em&gt;, with PyTorch a close second. I could not reproduce Tensorflow&amp;rsquo;s results, and it is not clear how to do it using the documentation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data preparation&lt;/strong&gt;: a tie with &lt;em&gt;Mxnet and Pytorch&lt;/em&gt;. Both frameworks use very similar &lt;code&gt;Dataset&lt;/code&gt; and &lt;code&gt;Dataloader&lt;/code&gt; interfaces. I was able to get going using this interface very fast. Keras also has a very similar interface using &lt;code&gt;Sequence&lt;/code&gt; class, but the absence of something similar to &lt;code&gt;Dataloader&lt;/code&gt; results in having to return batches rather than simply one image at a time. Also Tensorflow has a &lt;code&gt;Dataset&lt;/code&gt; interface which I used before but somehow made me feel I am programming in C all over again.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Speed&lt;/strong&gt;: &lt;em&gt;Pytorch&lt;/em&gt;. It is very obvious that Pytorch won the speed race all over the board. Also, although there is no information for only inference time in Tensorflow, it looks like Tensorflow also has the edge on Mxnet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After this quick experiment, I am really excited about working with Mxnet and see how it goes. It looks like a great choice for working with computer vision, even though those experiments show it is the slowest. I am excited to see if it is really worth ditching Tensorflow for it, as I test it for different deep learning applications.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;fab fa-github-square&#34; href=&#34;https://github.com/dibgerge/blog-tf-mxnet-pytorch&#34;&gt;Get the code!&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigations of degradation and encapsulation of plastic scintillator</title>
      <link>https://dibgerge.github.io/publication/2019-nimpr/</link>
      <pubDate>Tue, 05 Feb 2019 19:34:55 -0500</pubDate>
      <guid>https://dibgerge.github.io/publication/2019-nimpr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>In-situ fatigue monitoring procedure using nonlinear ultrasonic surface waves considering the nonlinear effects in the measurement system</title>
      <link>https://dibgerge.github.io/publication/2019-net/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2019-net/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ultrasound Modeling and Simulation: Status Update</title>
      <link>https://dibgerge.github.io/publication/2018-pnnl/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2018-pnnl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neural Interactive Machine Learning</title>
      <link>https://dibgerge.github.io/project/niml/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/niml/</guid>
      <description>&lt;p&gt;Machine intelligence advances have elevated the potential of computer-based video analytics but machines alone still fall short of human visual recognition capabilities. Humans, however, cannot address the high volumes of data in need of analysis. Despite exponential growth in machine analytics, opportunities for improvement remain (reducing training sets, improving cross-platform compatibility, adapting to changing environments, etc.). This project aims at achieving higher performance thresholds by integrating the strengths of human and machine reasoning.&lt;/p&gt;
&lt;p&gt;We are currently building brain-computer interfaces and machine learning approaches to quantify neurological data reflecting fast visual recognition collected with an electroencephalogram (EEG) headset worn by a human participant viewing video data. The quality of psychological engagement are being investigated and the quality of EEG signatures are being evaluated based on reproducibility and accuracy.&lt;/p&gt;
&lt;p&gt;The NIML approach is envisaged to significantly enhance data processing with application to HIL processes that could benefit big data problems such as data labeling for medicine, social media, among others.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Validation of Ultrasound NDE Simulation Models</title>
      <link>https://dibgerge.github.io/project/ut-modeling/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/ut-modeling/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Nondestructive_testing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Non-destructive evaluation and testing (NDE)&lt;/a&gt; is essential for ensuring the safety of operational nuclear power plants around the world. Ultrasonic testing is an NDE technique which is largely utilized for inspecting pipelines in the nuclear industry due to its ability to detect flaws hidden within the inner diameter of pipelines.&lt;/p&gt;
&lt;p&gt;Computer modeling and simulation is becoming an essential tool for transducer design and insight into ultrasonic nondestructive evaluation. For computational models to be of use in practical situations, it is important to develop techniques for inferring the reliability of inspections using simulated results. This includes information about the detectability of different defect types within different material varying in complexity and grain structure. To address this problem, we need to develop techniques to quantify confidence in simulations, and methods to incorporate experimental and structural noise into model outputs.&lt;/p&gt;
&lt;p&gt;In this project, we are building a large database of ultrasound inspection empirical data using different types of probes, materials, and defects. We are using this empirical data to: (1) Develop techniques for validating ultrasound inspection simulations; (2) Uncertainty quantification due to uncertain or unknown simulation input parameters; and (3) Develop noise models which can be fused with simulation data for analyzing inspection reliability using simulated data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ensembles of novelty detection classifiers for structural health monitoring using guided waves</title>
      <link>https://dibgerge.github.io/publication/2017-sms/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-sms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Challenges and Solutions in SHM for Nuclear Power Environments</title>
      <link>https://dibgerge.github.io/publication/2017-iwshm/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-iwshm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the usage of ultrasound computational models for decision making under ambiguity</title>
      <link>https://dibgerge.github.io/publication/2017-qnde/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Preliminary design of high temperature ultrasonic transducers for liquid sodium environments</title>
      <link>https://dibgerge.github.io/publication/2017b-qnde/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Integration and Assessment of Component Health Prognostics in Supervisory Control Systems</title>
      <link>https://dibgerge.github.io/publication/2017-npic/</link>
      <pubDate>Sun, 11 Jun 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-npic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Validation of Ultrasonic Nondestructive Examination (NDE) Computational Models – Phase 1</title>
      <link>https://dibgerge.github.io/publication/2017-pnnl/</link>
      <pubDate>Fri, 05 May 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-pnnl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Detecting Water in Dry Storage Canisters for Used Fuel</title>
      <link>https://dibgerge.github.io/publication/2017-ihlrwm/</link>
      <pubDate>Sun, 09 Apr 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-ihlrwm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PVT Degradation Studies: Acoustic Diagnostics</title>
      <link>https://dibgerge.github.io/publication/2017-osti/</link>
      <pubDate>Sat, 01 Apr 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Learning and Statistical Signal Processing for Guided Wave Structural Health Monitoring</title>
      <link>https://dibgerge.github.io/project/gwshm/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/project/gwshm/</guid>
      <description>&lt;p&gt;Sparse ultrasonic guided waves sensor networks would increase safety and reduce maintenance costs of current civil and industrial structures by providing continuous information about structural health. Common damage modalities that are of concern include fatigue cracks and corrosion in metals, and delaminations and impact damage in composite materials. Ultrasonic guided wave testing is used in various industries due to its superior ability to rapidly inspect large areas in thin structures. Guided waves travel long distances and interrogate the entire thickness of a structure. These properties make guided waves of interest in structural health monitoring (SHM) since a small number of transducers is required to monitor a large structure.&lt;/p&gt;
&lt;p&gt;Due to the complexity of guided wave signals, detection strategies in guided wave SHM often are based on detecting changes in the signals based on reference signals collected when the structure is in its pristine state. Damage detection is challenging because there are multitude of other factors that affect the signal such as sensor aging, temperature changes, humidity, and/or varying loading conditions.&lt;/p&gt;
&lt;p&gt;In this project, we developed machine learning and statistical signal processing techniques for building reliable and efficient methods for damage classification in structures under varying environmental and operating conditions. In addition, we developed statistical methods for quantifying the probability of detection due to sensor aging and variations in environmental and operating condition.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Summary Describing Integration of ERM Methodology into Supervisory Control Framework with Software Package Documentation</title>
      <link>https://dibgerge.github.io/publication/2016-osti/</link>
      <pubDate>Tue, 20 Sep 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2016-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Experimental Design for Evaluating Selected Nondestructive Measurement Technologies</title>
      <link>https://dibgerge.github.io/publication/2016b-osti/</link>
      <pubDate>Sat, 16 Jul 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2016b-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ultrasound Sensors and Methods for Nuclear Power Plant Environments</title>
      <link>https://dibgerge.github.io/project/ut-sensors/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/ut-sensors/</guid>
      <description>&lt;center&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box fancy-figure caption-position-bottom caption-effect-fade&#34; style=&#34;max-width:400px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;featured.png&#34; alt=&#34;Schematic of nuclear power plant components which require monitoring using NDE techniques.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;featured.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Schematic of nuclear power plant components which require monitoring using NDE techniques.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;p&gt;This is a topic co project focuses on demonstration of ultrasound sensing technology and techniques for various applications related to nuclear power plant life cycle, next generation advanced reactors, and radiation monitoring at border portals. The focus of this research has been on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assessment of  conventional ultrasound and non-linear ultrasound non-destructive evaluation techniques capable of detecting impending damage before crack formation. This project focuses on creep and fatigue damage modalities in nuclear power plants.&lt;/li&gt;
&lt;li&gt;Development of high temperature ultrasound sensor probes, capable of withstanding temperatures up to 550 C for extended period of time. Also, the sensors are designed to be capable of reliable damage detection in sodium coolants.&lt;/li&gt;
&lt;li&gt;Assessment of ultrasound inspection reliability under challenging environments, and sensor calibration and methods for compensating sensor aging.&lt;/li&gt;
&lt;li&gt;Water detection in spent fuel dry cask storage canisters.&lt;/li&gt;
&lt;li&gt;Fog detection in PVT scintillators used at border portals for radiation detection. Fog build up in those plastic detectors reduce their sensitivity. We assessed ultrasound techniques for predicting fogging levels in the detectors.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Non-destructive Measurements for Diagnostics of Advanced Reactor Passive Components</title>
      <link>https://dibgerge.github.io/publication/2016-icapp/</link>
      <pubDate>Sun, 17 Apr 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2016-icapp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Design and performance of optimal detectors for guided wave structural health monitoring</title>
      <link>https://dibgerge.github.io/publication/2016-shm/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2016-shm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Guided Wave Structural Health Monitoring for Impact Damage Detection and Characterization</title>
      <link>https://dibgerge.github.io/publication/2015-asc/</link>
      <pubDate>Thu, 01 Oct 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-asc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>State of the Art Assessment of NDE Techniques for Aging Cable Management in Nuclear Power Plants FY2015</title>
      <link>https://dibgerge.github.io/publication/2015-osti/</link>
      <pubDate>Tue, 08 Sep 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assessment of NDE for key indicators of aging cables in nuclear power plants – Interim status</title>
      <link>https://dibgerge.github.io/publication/2015b-qnde/</link>
      <pubDate>Mon, 20 Jul 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Experimental validation of ultrasonic NDE simulation software</title>
      <link>https://dibgerge.github.io/publication/2015-qnde/</link>
      <pubDate>Mon, 20 Jul 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Progress towards prognostic health management of passive components in advanced reactors: Model selection and evaluation</title>
      <link>https://dibgerge.github.io/publication/2015-phm/</link>
      <pubDate>Mon, 22 Jun 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-phm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Component-Level Prognostics Health Management Framework for Passive Components</title>
      <link>https://dibgerge.github.io/publication/2015b-osti/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015b-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rotating field EC-GMR sensor for crack detection at fastener site in layered structures</title>
      <link>https://dibgerge.github.io/publication/2015-ieee-sensors/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-ieee-sensors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EC-GMR array with rotating current excitation for multilayered riveted structures inspection</title>
      <link>https://dibgerge.github.io/publication/2014-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feasibility of PZT ceramics for impact damage detection in composite structures</title>
      <link>https://dibgerge.github.io/publication/2014d-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014d-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image processing algorithms for automated analysis of GMR data from inspection of multilayer structures</title>
      <link>https://dibgerge.github.io/publication/2014c-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014c-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multitechnique monitoring of fatigue damage in adhesively bonded composite lap-joints</title>
      <link>https://dibgerge.github.io/publication/2014b-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Giant Magnetoresistance Sensors for Aircraft Inspection</title>
      <link>https://dibgerge.github.io/project/gmr/</link>
      <pubDate>Tue, 01 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/gmr/</guid>
      <description>&lt;p&gt;Nondestructive inspection of multi-layered airframe geometries is a significant challenge largely due to complexity of test geometry and deep lying defects. Structural geometry of interest includes different configurations of aircraft skins, stringers, doublers, wing-splice with fasteners and deep lying cracks and corrosion. Inspection of these complex geometries requires dealing with a large number of variables which affect damage detection performance (material, size, thickness, edges, air gaps, etc.), experimental sensor system (frequency, waveform shape, harmonics, sampling intervals, circuit design etc.), and defect variables (length, width, volume, shape, distribution, orientation, etc.). Combination of these classes of variables encountered in any inspection makes the interpretation of the signals very challenging.&lt;/p&gt;
&lt;p&gt;The purpose of this project was to design, fabricate and test a novel transducer and inspection technique for detecting cracks near fastener sites in aircrafts with high efficiency and sensitivity. The transducer uses Giant Megnetoresistance (GMR) sensor arrays for increasing sensitivity and reducing required aircraft scan times. Also, a rotating coil excitation is used, which allows the probe to be uniformly sensitive to cracks oriented in arbitrary direction. This is a significant advancement over the previous state-of-the-art, where probes were only sensitive to cracks oriented parallel to the direction of coil current flow. A finite element model (FEM) was also developed for simulating the designed probes. FEM simulations were then used for optimizing the probe design, including GMR sensor placement, excitation coil parameters, and signal processing methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Advanced Signal Processing Algorithms in Structural Integrity Monitoring</title>
      <link>https://dibgerge.github.io/publication/2014-icons/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2014-icons/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Wireless Sensor Node for Structural Health Monitoring using Guided Wave Testing</title>
      <link>https://dibgerge.github.io/publication/2013-me/</link>
      <pubDate>Tue, 01 Oct 2013 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2013-me/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Novel Mode Decomposition Algorithms for Lamb Wave Signal Analysis in Online Monitoring of Structures</title>
      <link>https://dibgerge.github.io/publication/2013-ejam/</link>
      <pubDate>Thu, 14 Mar 2013 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2013-ejam/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sensor-tilt invariance analysis for eddy current signals</title>
      <link>https://dibgerge.github.io/publication/2012-ndte/</link>
      <pubDate>Thu, 01 Nov 2012 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2012-ndte/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pre-processing methods for eddy current data analysis using Hilbert-Huang Transform</title>
      <link>https://dibgerge.github.io/publication/2011-isaem/</link>
      <pubDate>Wed, 05 Sep 2012 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2011-isaem/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eddy Current Inspection Autoanalysis of Steam Generator Tubes in Nuclear Power Plants</title>
      <link>https://dibgerge.github.io/project/autoanalysis/</link>
      <pubDate>Fri, 01 Jun 2012 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/autoanalysis/</guid>
      <description>&lt;center&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box fancy-figure caption-position-bottom caption-effect-fade&#34; style=&#34;max-width:400px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;featured.png&#34; alt=&#34;Processing pipeline for autoanalysis software.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;featured.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Processing pipeline for autoanalysis software.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;p&gt;Steam generators (SG) are heat exchanger units used in nuclear power plants. Each SG unit typically contains 10000 - 20000 tubes which are exposed to harsh environmental conditions such as high temperatures, high pressures, high fluid flow rates and material interactions resulting in various types of tube degradations - mechanical wear, stress corrosion cracking (SCC), pitting, volumetric degradation, inter granular attack (IGA), loose parts and denting. Electromagnetic methods at low frequencies such as eddy current (EC) have been widely used for inspecting SG tubes. Generally, trained experts will analyze the acquired data looking for any damage indication. However, due to the large volume of data, manual inspection is highly susceptible for a person to miss an indication of damage in the data. The goal of this project is to automate damage detection and classification for eddy current inspection of steam generator tubes in nuclear power plants.&lt;/p&gt;
&lt;p&gt;The automated signal analysis system pipeline involves 1) pre-processing and region of interest (ROI) detection, 2) feature extraction and 3) classification. We used physics based feature extraction and machine learning techniques to automate and enhance the current state-of-the-art performance of manual signal analysis. We tested the pipelines using data from a performance demonstration database consisting of on-site inspection data obtained from multiple nuclear power plants in the USA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>High performance wireless sensors system for structural health monitoring</title>
      <link>https://dibgerge.github.io/publication/2011-qnde/</link>
      <pubDate>Fri, 22 Jul 2011 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2011-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nonlinear, non-stationary image processing technique for eddy current NDE</title>
      <link>https://dibgerge.github.io/publication/2011b-qnde/</link>
      <pubDate>Fri, 22 Jul 2011 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2011b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wireless NDE sensor system for continuous monitoring</title>
      <link>https://dibgerge.github.io/publication/2010-qnde/</link>
      <pubDate>Thu, 22 Jul 2010 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2010-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wireless Senor Networks for Structural Health Monitoring</title>
      <link>https://dibgerge.github.io/project/wsn/</link>
      <pubDate>Tue, 27 Apr 2010 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/wsn/</guid>
      <description>&lt;div style=&#34;text-align: center;&#34;&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box fancy-figure caption-position-bottom caption-effect-fade&#34; style=&#34;max-width:400px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;featured.jpg&#34; alt=&#34;Schematic of sensor network with centralized architecture.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;featured.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Schematic of sensor network with centralized architecture.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;The use of wireless sensor networks in structural health monitoring can significantly increase safety and reduce manufacturing and maintenance costs. In this project, we integrate guided wave sensors with wireless sensor modules for continuous monitoring of civil structures. The wireless sensors eliminate the need for cables, reducing overall structure weight (especially important in aerospace industry) and single points of failure. We designed sensor interface boards for the Iris wireless nodes allowing transmitting and receiving guided waves using piezoelectric sensors. A distributed control algorithm is also implemented for controlling a wireless sensor network from a base station.



&lt;div class=&#34;gallery caption-position-center caption-effect-fade hover-effect-zoom hover-transition&#34; itemscope itemtype=&#34;http://schema.org/ImageGallery&#34;&gt;
	  
  

&lt;div class=&#34;box&#34; style=&#34;max-width:300px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://dibgerge.github.io/project/wsn/wsn_board.png&#39;);&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;project/wsn/wsn_board.png&#34; alt=&#34;Sensor interface circuit board for guided wave reception.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;wsn_board.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Sensor interface circuit board for guided wave reception.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

  

&lt;div class=&#34;box&#34; style=&#34;max-width:300px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://dibgerge.github.io/project/wsn/wsn_demo.jpg&#39;);&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;project/wsn/wsn_demo.jpg&#34; alt=&#34;Two sensor nodes configured for in transmit-receive mode.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;wsn_demo.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Two sensor nodes configured for in transmit-receive mode.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
