<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ge[o]rges Dib</title>
    <link>https://dibgerge.github.io/</link>
      <atom:link href="https://dibgerge.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Ge[o]rges Dib</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 12 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dibgerge.github.io/images/icon_hufb0bba0b24038dd6774d907c032416d0_44829_512x512_fill_lanczos_center_2.png</url>
      <title>Ge[o]rges Dib</title>
      <link>https://dibgerge.github.io/</link>
    </image>
    
    <item>
      <title>Hashing</title>
      <link>https://dibgerge.github.io/tutorial/algorithms/2_hashing/</link>
      <pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://dibgerge.github.io/tutorial/algorithms/2_hashing/</guid>
      <description>&lt;h2 id=&#34;basics&#34;&gt;Basics&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Sorting</title>
      <link>https://dibgerge.github.io/tutorial/algorithms/1_sorting/</link>
      <pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://dibgerge.github.io/tutorial/algorithms/1_sorting/</guid>
      <description>&lt;p&gt;The general framework we have in sorting is that we are given a sequence of $n$ numbers, and we want to construct an algorithm which orders those numbers from smallest to largest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;: A sequence of $n$ numbers $\langle a_1, a_2, \cdots, a_n \rangle$ &lt;br&gt;
&lt;strong&gt;Output&lt;/strong&gt;: A permutation (or reordering)   $\langle a_1&amp;rsquo;, a_2&amp;rsquo;, \cdots, a_n&amp;rsquo; \rangle$ of the inputs such that $a_1&amp;rsquo; \le a_2&amp;rsquo; \le \cdots \le a_n&#39;$.&lt;/p&gt;
&lt;p&gt;In general, the items we would like to sort do not have to be numbers, as they can also be objects, which some sense of ordering for them, as we will see later.&lt;/p&gt;
&lt;p&gt;In the following we describe some of the most common sorting algorithms.&lt;/p&gt;
&lt;h2 id=&#34;insertion-sort&#34;&gt;Insertion sort&lt;/h2&gt;
&lt;p&gt;This is an efficient algorithm for sorting a small number of elements. Works the way many people would sort a hand of playing cards! Every time the dealer hands you a card, you insert this card in the correct position within your current hand. To do this, you compare it with each of the cards already in hard, from left to right.&lt;/p&gt;
&lt;h3 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def insertion_sort(a):
    for j in range(1, len(a)):
        key = a[j]
        i = j - 1
        while i &amp;gt;= 0 and a[i] &amp;gt; key:
            a[i+1] = a[i]
            i = i - 1
        a[i + 1] = key
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Best case scenario is when array is sorted, we have linear time $O(n)$. Worst case scenario when array sorted in reverse order, we have $O(n^2)$.&lt;/p&gt;
&lt;p&gt;Another flavors of insertion sort is using a recursive procedure where we recursively sort &lt;code&gt;A[1..n-1]&lt;/code&gt; and then insert &lt;code&gt;A[n]&lt;/code&gt; into the sorted array &lt;code&gt;A[1..n-1]&lt;/code&gt;.&lt;br&gt;
Another faster way is to implement binary search within the while loop, which has $O(\lg n)$ time instead of linear search time for insertion position.&lt;/p&gt;
&lt;h2 id=&#34;selection-sort&#34;&gt;Selection Sort&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def selection_sort(a):
    for i in range(len(a)-1):
        min_idx = i
        for j in range(i+1, len(a)):
            if a[j] &amp;lt; a[min_idx]:
                min_idx = j

        if min_idx != i:
            a[i], a[min_idx] = a[min_idx], a[i]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finds the smallest element in 2 and replace with &lt;code&gt;a[0]&lt;/code&gt;, second smallest and replace with &lt;code&gt;a[1]&lt;/code&gt;, etc&amp;hellip;&lt;/p&gt;
&lt;p&gt;Best and worst running times are the same and they are $O(n^2)$.&lt;/p&gt;
&lt;h2 id=&#34;merge-sort&#34;&gt;Merge Sort&lt;/h2&gt;
&lt;p&gt;Divide an $n$-element sequence into two subsequences of sizes $n/2$ each. Recursively sort the two subsequences and merge them after sorting.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
def merge(A, p, q, r):
    &amp;quot;&amp;quot;&amp;quot;
    Merges the two sorted sub-arrays A[p:q] and A[q+1:r] such that the
    final subarray a[q:r] is in sorted order.

    Parameters
    ----------
    A : list
        A list of numbers of size `n`.

    p : int
        The begin index of the left array.

    q : int
        The begin index of the right array, and 1 + end index of left array.

    r : int
        End index of right array + 1.

    Return
    ------
    : None
        This function sorts array `A` in-place.
    &amp;quot;&amp;quot;&amp;quot;
    L, R = A[p:q], A[q:r]
    i, j = 0, 0

    for k in range(p, r):
        try:
            if L[i] &amp;lt;= R[j]:
                A[k] = L[i]
                i += 1
            else:
                A[k] = R[j]
                j += 1
        except IndexError:
            if i &amp;gt;= len(L):
                A[k] = R[j]
                j += 1
            elif j &amp;gt;= len(R):
                A[k] = L[i]
                i += 1


def merge_sort(a, p=0, r=None):
    if r is None:
        r = len(a)

    if r - p &amp;gt; 1:
        q = (p + r)//2
        merge_sort(a, p, q)
        merge_sort(a, q, r)
        merge(a, p, q, r)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Merge sort has a running time of $O(n\lg n)$.&lt;/p&gt;
&lt;h2 id=&#34;bubble-sort&#34;&gt;Bubble sort&lt;/h2&gt;
&lt;h2 id=&#34;heap-sort&#34;&gt;Heap sort&lt;/h2&gt;
&lt;p&gt;We first need to define what is a heap.&lt;/p&gt;
&lt;h2 id=&#34;quick-sort&#34;&gt;Quick sort&lt;/h2&gt;
&lt;h2 id=&#34;count-sort&#34;&gt;Count sort&lt;/h2&gt;
&lt;h2 id=&#34;radix-sort&#34;&gt;Radix sort&lt;/h2&gt;
&lt;h2 id=&#34;sorting-in-python&#34;&gt;Sorting in python&lt;/h2&gt;
&lt;p&gt;In python, there is the built in algorithm &lt;code&gt;sorted()&lt;/code&gt;.  So what algorithm does this function use?&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Elimination</title>
      <link>https://dibgerge.github.io/tutorial/math-linear-algebra/part-01-elimination/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/tutorial/math-linear-algebra/part-01-elimination/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The geometry of linear equations</title>
      <link>https://dibgerge.github.io/tutorial/math-linear-algebra/part-01-intro/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/tutorial/math-linear-algebra/part-01-intro/</guid>
      <description>&lt;p&gt;The fundamental problem of linear algebra is to solve $n$ linear equations in $n$ unknowns, for example:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
&amp;amp; 2x - y &amp;amp;= 0 \\\&lt;br&gt;
&amp;amp; \text{&amp;ndash;}x + 2y &amp;amp;= 3
\end{align}
$$&lt;/p&gt;
&lt;p&gt;In linear algebra, we view this problem in three ways.&lt;/p&gt;
&lt;h2 id=&#34;row-picture&#34;&gt;Row picture&lt;/h2&gt;
&lt;p&gt;Plot the points that satisfy each equation. In the above example, each equation represents a line in a 2-D space. The intersection of the two plots represent the solution to this system of equations. Figure 1 shows the plot for the two equations above, and they intersect at one point ($x=1$, $y=2$), which is the system&#39;s solution.&lt;/p&gt;
&lt;center&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box&#34; &gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://dibgerge.github.io/tutorials/math-linear-algebra/Figures/part-01-row-picture.png&#34; alt=&#34;Figure 1: The lines $2x -y = 0$ and $-x&amp;#43;2y=3$ intersect at the point (1, 2).&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://dibgerge.github.io/tutorials/math-linear-algebra/Figures/part-01-row-picture.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Figure 1: The lines $2x -y = 0$ and $-x&amp;#43;2y=3$ intersect at the point (1, 2).&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;h2 id=&#34;column-picture&#34;&gt;Column picture&lt;/h2&gt;
&lt;p&gt;We rewrite the system of linear equations as a single equation by turning the coefficients in the columns of the system into vectors:
$$
x \begin{bmatrix} 2 \\\ \text{&amp;ndash;}1 \end{bmatrix} + y \begin{bmatrix} \text{&amp;ndash;}1 \\\ 2 \end{bmatrix} = \begin{bmatrix} 0 \\\ 3 \end{bmatrix}
$$
where we view the right  hand side as a linear combinations of the coefficients on the left hand side. Geometrically, we want to find numbers $x$ and $y$ so that $x$ so that the combinations of the two columns vectors equals $\begin{bmatrix} 0 \\\ 3 \end{bmatrix}$. Figure 2 shows that for $x=1$ and $y=2$, we get the correct combination to give us the right hand side.&lt;/p&gt;
&lt;center&gt;
  

&lt;div class=&#34;box&#34; &gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://dibgerge.github.io/tutorials/math-linear-algebra/Figures/part-01-column-picture.png&#34; alt=&#34;Figure 2: A linear combination of the column vectors equals the vector $\mathbf{b}$. &#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://dibgerge.github.io/tutorials/math-linear-algebra/Figures/part-01-column-picture.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Figure 2: A linear combination of the column vectors equals the vector $\mathbf{b}$. &lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;h2 id=&#34;matrix-picture&#34;&gt;Matrix picture&lt;/h2&gt;
&lt;p&gt;We write the system of equations as a single equation by using matrices and vectors. The above equation is:&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix}
2 &amp;amp; \text{&amp;ndash;}1 \\\&lt;br&gt;
\text{&amp;ndash;} 1 &amp;amp; 2
\end{bmatrix}
\begin{bmatrix}
x \\\ y
\end{bmatrix}=
\begin{bmatrix}
0 \\\ 3
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;The matrix $A = \begin{bmatrix}2 &amp;amp; \text{&amp;ndash;}1 \\\ \text{&amp;ndash;} 1 &amp;amp; 2\end{bmatrix}$ is called the &lt;em&gt;coefficient matrix&lt;/em&gt;. The vector $\mathbf{x} = \begin{bmatrix} x \\\ y \end{bmatrix}$ is the vector of unknowns. The values on the right hand side of the equations form the vector $\mathbf{b}$:
$$
A \mathbf{x} = \mathbf{b}
$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow, PyTorch, and MxNet</title>
      <link>https://dibgerge.github.io/post/tf-mxnet-pytorch/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/post/tf-mxnet-pytorch/</guid>
      <description>&lt;p&gt;In the past 2 years, I have been exclusively using Tensorflow with Keras for training and testing deep neural networks. I never really thought twice about it, because this is what everyone else seems to be using. I mean, just looking at the popularity of those frameworks in github compared with their closest competitors was enough to make the decision for me. Here are the approximate statistics as of March 2019 for the four most popular frameworks.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow&#34;&gt;Tensorflow&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/keras-team/keras&#34;&gt;Keras&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/pytorch/pytorch&#34;&gt;Pytorch&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/apache/incubator-mxnet&#34;&gt;Mxnet&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Github &lt;i class=&#34;fas fa-star&#34;&gt;&lt;/i&gt;&lt;/td&gt;
&lt;td&gt;122,500&lt;/td&gt;
&lt;td&gt;39,000&lt;/td&gt;
&lt;td&gt;25,500&lt;/td&gt;
&lt;td&gt;16,500&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Recently, I have been going through the lectures of &lt;a href=&#34;fast.ai&#34;&gt;Jeremy Howard&#39;s Fast.ai&lt;/a&gt; excellent class, where they use Pytorch as the backend of the high-level library they built. This was one of the reasons I started questioning what was I missing by limiting myself to Tensorflow. Also, I have seen the extensive vision library of &lt;a href=&#34;https://gluon-cv.mxnet.io/index.html&#34;&gt;MxNet&#39;s GluonCV&lt;/a&gt;, and this really made me feel that I might be missing out.&lt;/p&gt;
&lt;p&gt;In addition to all the fear of missing out stuff, I was coding my own implementation of &lt;a href=&#34;https://gluon-cv.mxnet.io/index.html&#34;&gt;ResNet&lt;/a&gt;, and I scoured online the plethora of different implementations of ResNet, some with lots of &lt;i class=&#34;fas fa-star&#34;&gt;s&lt;/i&gt;. I realized that many had implementation details which differed from the original paper, and it was not clear if it is intentional or not. Thus I really though that a test in reproducibility is due and so I did.&lt;/p&gt;
&lt;p&gt;I set out to compare the three frameworks: tensorflow, pytorch, and mxnet. I wanted to use some of the built-in convolutional neural networks with built-in pre-trained weights to directly classify Imagenet&#39;s validation dataset images. Throughout this comparison, I was looking for three factors:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ease of loading the dataset and reproducing the pre-processing steps required before feeding images to the neural network for classification.&lt;/li&gt;
&lt;li&gt;Computed error rate vs framework&#39;s reported error. It would be also nice to compare the results with the original publication, but most report validation error using 10-crops, and here we use only single crop.&lt;/li&gt;
&lt;li&gt;Inference speed.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;dataset-and-convolutional-neural-network-architectures&#34;&gt;Dataset and Convolutional Neural Network Architectures&lt;/h2&gt;
&lt;p&gt;The datatset I used was Imagenet&#39;s validation dataset which constitutes of 50,000 images with different sizes. The easiest way to get your hands on the data is to download it from Kaggle &lt;a href=&#34;https://www.kaggle.com/c/imagenet-object-localization-challenge&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the frameworks, I used the following versions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tensorflow 1.13&lt;/strong&gt; with Keras as the front-end interface (Note this is different from using Keras with Tensorflow backend since now Tensorflow comes packed with its own Keras version, which is not compatible with other frameworks).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyTorch 1.0.1&lt;/strong&gt; with PyTorch vision for convolutional neural networks implementations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MxNet 1.4&lt;/strong&gt; with GluonCV for convolutional neural networks implementaitons&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the convolutional neural network, I considered four different architectures: &lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34;&gt;ResNet50&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34;&gt;Resnet101&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1704.04861&#34;&gt;Mobilenet&lt;/a&gt;, and &lt;a href=&#34;https://arxiv.org/abs/1608.06993&#34;&gt;Densenet121&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The top 1 error published on each frameworks&amp;rsquo; website, based on a single center crop evaluation is as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://github.com/keras-team/keras-applications&#34;&gt;Tensorflow (Keras)&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://pytorch.org/docs/stable/torchvision/models.html&#34;&gt;Pytorch&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href=&#34;https://gluon-cv.mxnet.io/model_zoo/classification.html&#34;&gt;Mxnet (GluonCV)&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;25.10&lt;/td&gt;
&lt;td&gt;23.85&lt;/td&gt;
&lt;td&gt;22.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;23.60&lt;/td&gt;
&lt;td&gt;22.63&lt;/td&gt;
&lt;td&gt;21.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;29.60&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;26.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;25.0&lt;/td&gt;
&lt;td&gt;25.35&lt;/td&gt;
&lt;td&gt;25.03&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We note here that the error for Resnet101 is reported in Keras Applications, but Resnet101 is not packaged with Tensorflow 1.13, which is used in this experiment, and thus we won&#39;t have any results for it. Also, Pytorch does not come packaged with an implementation of Mobilenet.&lt;/p&gt;
&lt;p&gt;Also, it is interesting to see that especially for Resnet implementations, it is obvious that the accuracy of Mxnet &amp;gt; PyTorch &amp;gt; Tensorflow.&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;All the code used here can be found on &lt;a href=&#34;https://github.com/dibgerge/blog-tf-mxnet-pytorch&#34;&gt;github&lt;/a&gt;. The biggest challenge here really is loading and pre-processing the images the right way. The following briefly describes how I did it for each of the three frameworks.&lt;/p&gt;
&lt;h3 id=&#34;tensorflow-pre-processing&#34;&gt;Tensorflow pre-processing&lt;/h3&gt;
&lt;p&gt;Uses the &lt;code&gt;Sequence&lt;/code&gt; abstract class for loading the data using a a generator. The pre-processing pipeline is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Resized the shorter side of the image to 256 pixels (implemented manually).&lt;/li&gt;
&lt;li&gt;Center cropped the image to 224 x 224 pixels (implemented manually).&lt;/li&gt;
&lt;li&gt;Apply the function &lt;code&gt;preprocess_input&lt;/code&gt; which applies the appropriate normalization based on how the network is trained. This function is provided with each different architecture built-in Tensorflow&#39;s Keras frontend.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;pytorch-pre-processing&#34;&gt;Pytorch pre-processing&lt;/h3&gt;
&lt;p&gt;Used the &lt;code&gt;Dataset&lt;/code&gt; and &lt;code&gt;Dataloader&lt;/code&gt; interfaces to feed the data to the neural network. The standard pipeline for pre-processing images for all architectures is documented and is a composition of four transforms using Pytorch&#39;s &lt;code&gt;transforms&lt;/code&gt; API:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Resize image to 256 pixels (using &lt;code&gt;transforms.Resize&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Center image to 224 pixels (using &lt;code&gt;transforms.CenterCrop&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Convert images to pytorch tensor (using &lt;code&gt;transforms.ToTensor&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Normalize image by mean subtraction and standard deviation scaling (using &lt;code&gt;transforms.Normalize&lt;/code&gt;). The normalization values are given in the Pytorch&#39;s documentation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;mxnet-pre-processing&#34;&gt;Mxnet pre-processing&lt;/h3&gt;
&lt;p&gt;Used the &lt;code&gt;Dataset&lt;/code&gt; and &lt;code&gt;Dataloader&lt;/code&gt; interfaces to feed the data to the neural network. Mxnet comes packaged with a preset function which applies the required pipeline for models pre-trained on imagenet, using the &lt;code&gt;gluoncv.data.transforms.presets.imagenet.transform_eval&lt;/code&gt; function.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;The following table summarizes the achieved error percentages for each of the four architectures using the three different frameworks.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;(% error)&lt;/th&gt;
&lt;th&gt;Tensorflow&lt;/th&gt;
&lt;th&gt;Pytorch&lt;/th&gt;
&lt;th&gt;Mxnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;26.92&lt;/td&gt;
&lt;td&gt;23.87&lt;/td&gt;
&lt;td&gt;22.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;22.63&lt;/td&gt;
&lt;td&gt;21.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;29.91&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;26.73&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;26.69&lt;/td&gt;
&lt;td&gt;25.57&lt;/td&gt;
&lt;td&gt;25.10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Interestingly, although I had the most experience with Keras, I could not reproduce the published results for Resnet and Densenet. This is probably because I had to manually implement the image resizing and cropping, which might be different one used to generate the published results. On the other hand, Pytorch provides the required documentation to be able to reproduce the results very closely. MxNet takes it even a step further by providing a single function which applies all required pre-processing, and the results match very well with published ones.&lt;/p&gt;
&lt;p&gt;As for running times, I measured the total running time for classifying 50,000 images.  All predictions were made on GPU (Nvidia GTX 1080 Ti), while the image pre-processing was made on CPU. The following tables summarizes the running time results in seconds. &lt;strong&gt;Please take those results with a huge grain of salt, since times vary a lot when loading and reloading large data from disk&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;(seconds)&lt;/th&gt;
&lt;th&gt;Tensorflow&lt;/th&gt;
&lt;th&gt;Pytorch&lt;/th&gt;
&lt;th&gt;Mxnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;137&lt;/td&gt;
&lt;td&gt;119&lt;/td&gt;
&lt;td&gt;140&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;159&lt;/td&gt;
&lt;td&gt;214&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;82&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;118&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;173&lt;/td&gt;
&lt;td&gt;120&lt;/td&gt;
&lt;td&gt;195&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;First, those results are somehow unfair to tensorflow. This is because I used threading with 4 workers for pre-processing images in Tensorflow, while 4 workers with multiprocessing was used for MxNet and Pytorch. But, this is rather Tensorflow/keras fault due to a &lt;a href=&#34;https://github.com/keras-team/keras/issues/10855&#34;&gt;bug&lt;/a&gt; not allowing me to use multiprocessing. Also, for Mxnet and Pytorch I measured the average time it took to classify 10 images (the batch size used). I did not do this in Tensorflow, because there is no easy way to measure per-batch times.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;(milliseconds)&lt;/th&gt;
&lt;th&gt;Tensorflow*&lt;/th&gt;
&lt;th&gt;Pytorch&lt;/th&gt;
&lt;th&gt;Mxnet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Resnet50&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;6.7 $\pm$ 4.3&lt;/td&gt;
&lt;td&gt;12.1 $\pm$ 1.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Resnet101&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;11.8 $\pm$ 1.2&lt;/td&gt;
&lt;td&gt;21.0 $\pm$ 3.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mobilenet&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;6.7 $\pm$ 1.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Densenet121&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;td&gt;15.6 $\pm$ 1.7&lt;/td&gt;
&lt;td&gt;26.7 $\pm$ 3.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Most of the time here is being spent loading the data from disk, and the GPU is not fully utilized. For example, based on average inference of 10 images in Resnet50, it takes about 33.5 seconds to classify all 50,000 images using PyTorch and about 60.5 seconds using Mxnet. We can reduce total inference by more than half if the GPU is kept busy.
Thus, the importance of handling data appropriately if speed matters.&lt;/p&gt;
&lt;h2 id=&#34;who-is-the-winner&#34;&gt;Who is the winner?&lt;/h2&gt;
&lt;p&gt;I think this experiment allowed me to assess three things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Availability of pre-trained networks&lt;/strong&gt;: trophy goes to &lt;em&gt;Mxnet&lt;/em&gt;. The extensive vision library of architectures/preset image processing is very impressive. Jury still out on other domains (RL, NLP). Tensorflow is a second, and Pytorch did not have much architecture packaged with it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reproducibility&lt;/strong&gt;: Again, trophy to &lt;em&gt;Mxnet&lt;/em&gt;, with PyTorch a close second. I could not reproduce Tensorflow&#39;s results, and it is not clear how to do it using the documentation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data preparation&lt;/strong&gt;: a tie with &lt;em&gt;Mxnet and Pytorch&lt;/em&gt;. Both frameworks use very similar &lt;code&gt;Dataset&lt;/code&gt; and &lt;code&gt;Dataloader&lt;/code&gt; interfaces. I was able to get going using this interface very fast. Keras also has a very similar interface using &lt;code&gt;Sequence&lt;/code&gt; class, but the absence of something similar to &lt;code&gt;Dataloader&lt;/code&gt; results in having to return batches rather than simply one image at a time. Also Tensorflow has a &lt;code&gt;Dataset&lt;/code&gt; interface which I used before but somehow made me feel I am programming in C all over again.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Speed&lt;/strong&gt;: &lt;em&gt;Pytorch&lt;/em&gt;. It is very obvious that Pytorch won the speed race all over the board. Also, although there is no information for only inference time in Tensorflow, it looks like Tensorflow also has the edge on Mxnet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After this quick experiment, I am really excited about working with Mxnet and see how it goes. It looks like a great choice for working with computer vision, even though those experiments show it is the slowest. I am excited to see if it is really worth ditching Tensorflow for it, as I test it for different deep learning applications.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;fab fa-github-square&#34; href=&#34;https://github.com/dibgerge/blog-tf-mxnet-pytorch&#34;&gt;Get the code!&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Differentiation</title>
      <link>https://dibgerge.github.io/tutorial/mit1801/unit1-1-definition/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/tutorial/mit1801/unit1-1-definition/</guid>
      <description>&lt;h2 id=&#34;definition-of-a-derivative&#34;&gt;Definition of a Derivative&lt;/h2&gt;
&lt;p&gt;Consider a function $f(x)$ represented by the curve in Figure 1. The derivative of $f(x)$ at a point $x=x_0$, denoted by $f&amp;rsquo;(x_0)$, is the slope of the tangent line to the graph of $f(x)$ at the point $(x_0, f(x_0))$. A tangent line is the &lt;em&gt;limit&lt;/em&gt; of the secant lines joining points $P=(x_0, f(x_0))$ and $Q$ on the graph of $f(x)$ as $Q$ approaches $P​$.&lt;/p&gt;
&lt;center&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box&#34; &gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;../Figures/session-001-differentiation.png&#34; alt=&#34;Figure 1: A graph with secant and tangent lines.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;../Figures/session-001-differentiation.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Figure 1: A graph with secant and tangent lines.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;center&gt;


&lt;div class=&#34;box&#34; &gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;../Figures/session-001-secant.png&#34; alt=&#34;Figure 2: Geometric definition of the derivative.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;../Figures/session-001-secant.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Figure 2: Geometric definition of the derivative.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;p&gt;The slope of secant $PQ$ is rise divided by run, or the ratio $\frac{\Delta f}{\Delta x}$ as shown in Figure 2. As $Q$ gets closer to $P$, the distance $\Delta x$ goes to zero. Then, the derivate which is equivalent to the slope of tangent, can be expressed mathematically as:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$\begin{align}
m &amp;amp;= f&amp;rsquo;(x_0) \\\&lt;br&gt;
&amp;amp;= \lim_{Q \rightarrow P} \frac{\Delta f}{\Delta x} \nonumber \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{\Delta f}{\Delta x} \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}
\end{align}$$
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The last equation above is the algebraic definition of a derivative.&lt;/p&gt;
&lt;p&gt;&lt;canvas id=&#34;myCanvas&#34; width=&#34;200&#34; height=&#34;100&#34;
style=&#34;border:1px solid #c3c3c3;&#34;&gt;
Your browser does not support the canvas element.
&lt;/canvas&gt;&lt;/p&gt;
&lt;script&gt;
var canvas = document.getElementById(&#34;myCanvas&#34;);
var ctx = canvas.getContext(&#34;2d&#34;);
ctx.fillStyle = &#34;#FF0000&#34;;
ctx.fillRect(0,0,150,75);
&lt;/script&gt;
&lt;h3 id=&#34;common-derivative-properties&#34;&gt;Common derivative properties&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;When you take the derivative of an odd function, you always get an even function and vice versa.&lt;/li&gt;
&lt;li&gt;Differentiable implies continuous: If $f$ is differentiable at $x_0$, then $f$ is continuous at $x_0$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Proof&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A function is continuous if $\lim_{x \rightarrow x_0} f(x) - f(x_0) = 0$. We multiply and divide this by the same value:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\lim_{x \rightarrow x_0} f(x) - f(x_0) &amp;amp;= \lim_{x \rightarrow x_0} \frac{f(x)- f(x_0)}{x - x_0} \left(x - x_0\right) \\\&lt;br&gt;
&amp;amp;= f&amp;rsquo;(x) \cdot 0 \\\&lt;br&gt;
&amp;amp;= 0
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;notations&#34;&gt;Notations&lt;/h2&gt;
&lt;p&gt;In calculus, as in the English language, there are many ways to express the same thing. Here we mention two notations most commonly used in calculus: Leibniz&amp;rsquo; and Newton&#39;s notations. Newton and Leibniz both invented calculus independently, and there has been anonymity between them, in addition to controversy about &lt;a href=&#34;https://en.wikipedia.org/wiki/Leibniz%E2%80%93Newton_calculus_controversy&#34;&gt;who has first invented calculus&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We let $y = f(x)$, where $y$ is a variable representing the function $f$ at any given $x$. From the formula for the derivative, we represent &amp;ldquo;the change in $y$&amp;rdquo; as $\Delta y = \Delta f = f(x_0 + \Delta x) - f(x_0)$. On the other hand, the &amp;ldquo;change in $x$&amp;rdquo; is $\Delta x = x - x_0$.&lt;/p&gt;
&lt;h3 id=&#34;leibniz-notation&#34;&gt;Leibniz&amp;rsquo; notation&lt;/h3&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$\lim_{\Delta x \rightarrow 0} \frac{\Delta y}{\Delta x} \equiv \frac{dy}{dx}$$
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Using Leibniz&amp;rsquo; notation, we might also represent the derivative as $\frac{df}{dx}$, $\frac{d}{dx}f$, $\frac{d}{dx}y$. Notice that Leibniz&amp;rsquo; notation does not specify where the derivative is being evaluated (e.g. at $x_0$). However, it expresses the derivative as a ratio, which is more convenient than Newton&#39;s notation in certain situations.&lt;/p&gt;
&lt;h3 id=&#34;newtons-notation&#34;&gt;Newton&#39;s notation&lt;/h3&gt;
&lt;p&gt;The advantage of Newton&#39;s nation is that is compact representation of the derivative:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$\lim_{\Delta x \rightarrow 0} \frac{\Delta f}{\Delta x} \equiv f^\prime(x_0)$$
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Differentiation Rules</title>
      <link>https://dibgerge.github.io/tutorial/mit1801/unit1-2-rules/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/tutorial/mit1801/unit1-2-rules/</guid>
      <description>&lt;h2 id=&#34;derivative-of-a-sum&#34;&gt;Derivative of a sum&lt;/h2&gt;
&lt;p&gt;The derivative of the sum of two functions is the sum of the derivatives:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$ (u + v)^\prime(x) = u^\prime(x) + v^\prime(x) $$
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Where the function $(u+v)(x)$ is just a shorthand for $u(x) + v(x)$.&lt;/p&gt;
&lt;h3 id=&#34;proof&#34;&gt;Proof&lt;/h3&gt;
&lt;p&gt;Applying the definition of the derivative to $(u + v)(x)$, we get:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
(u+v)^\prime(x) &amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{(u+v)(x+\Delta x) - (u+v)(x)}{\Delta x} \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{u(x+\Delta x) + v(x + \Delta x) - u(x) - v(x)}{\Delta x} \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{u(x + \Delta x) - u(x)}{\Delta x} + \lim_{\Delta x \rightarrow 0} \frac{v(x + \Delta x) - v(x)}{\Delta x} \\\&lt;br&gt;
&amp;amp;= u^\prime(x) + v^\prime(x)
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;derivative-of-sin-x&#34;&gt;Derivative of $\sin x$&lt;/h2&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$ \sin^\prime x = \cos x $$
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;proof-1&#34;&gt;Proof&lt;/h3&gt;
&lt;p&gt;Begin with the definition of the derivative:&lt;/p&gt;
&lt;p&gt;$$ \frac{d}{dx} \sin x = \lim_{\Delta x \rightarrow 0} \frac{\sin (x + \Delta x) - \sin x}{\Delta x} $$&lt;/p&gt;
&lt;p&gt;Then, using the trigonometric identity:&lt;/p&gt;
&lt;p&gt;$$\sin(a + b) = \sin a \cos b + \sin b \cos a$$&lt;/p&gt;
&lt;p&gt;We untangle the $x$ from the $\Delta x$ as follows:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\frac{d}{dx} \sin x &amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{\sin x \cos \Delta x + \sin \Delta x \cos x - \sin x}{\Delta x}\\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \left[ \frac{\sin x \cos\Delta x - \sin x}{\Delta x} + \frac{\cos x \sin \Delta x}{\Delta x}\right] \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \left[ \frac{\sin x \left( \cos \Delta x - 1\right)}{\Delta x} + \frac{\cos x \sin \Delta x}{\Delta x} \right] \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \sin x \left( \frac{\cos \Delta x - 1}{\Delta x} \right) + \lim_{\Delta x \rightarrow 0} \cos x \left( \frac{\sin \Delta x}{\Delta x} \right)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Now, we have the limits:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
&amp;amp; \lim_{\Delta x \rightarrow 0} \frac{\cos \Delta x - 1}{\Delta x} &amp;amp;= 0 \\\&lt;br&gt;
&amp;amp; \lim_{\Delta x \rightarrow 0} \frac{\sin\Delta x}{\Delta x} &amp;amp;= 1
\end{align}$$&lt;/p&gt;
&lt;p&gt;Where a geometric proof of the limits can be found &lt;a href=&#34;https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/1.-differentiation/part-a-definition-and-basic-rules/session-8-limits-of-sine-and-cosine/MIT18_01SCF10_Ses8a.pdf&#34;&gt;here for $\frac{\sin x}{x}$&lt;/a&gt; and &lt;a href=&#34;https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/1.-differentiation/part-a-definition-and-basic-rules/session-8-limits-of-sine-and-cosine/MIT18_01SCF10_Ses8b.pdf&#34;&gt;here for $\frac{1 - \cos x}{x}$&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;and thus the derivative becomes:&lt;/p&gt;
&lt;p&gt;$$
\frac{d}{dx}\sin x =  \sin x \cdot 0 + \cos x \cdot 1 = \cos x
$$&lt;/p&gt;
&lt;p&gt;The above proof is based on the algebraic formula for the derivative. Another way to proof the derivative on $\sin x$ is geometrically, using the unit circle. &lt;a href=&#34;https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/1.-differentiation/part-a-definition-and-basic-rules/session-8-limits-of-sine-and-cosine/MIT18_01SCF10_Ses8d.pdf&#34;&gt;This document provides a geometric proof&lt;/a&gt; for the derivative of $\sin x$.&lt;/p&gt;
&lt;h2 id=&#34;derivative-of-cos-x&#34;&gt;Derivative of $\cos x$&lt;/h2&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$ \cos^\prime x = -\sin x $$
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;proof-2&#34;&gt;Proof&lt;/h3&gt;
&lt;p&gt;The proof is very similar to that of the derivative of $\sin x$. Starting from the definition of the derivative:&lt;/p&gt;
&lt;p&gt;$$\frac{d}{dx} \cos x = \lim_{\Delta x \rightarrow 0} \frac{\cos(x + \Delta x) - \cos(x)}{\Delta x}$$&lt;/p&gt;
&lt;p&gt;Using the trigonometric identity:&lt;/p&gt;
&lt;p&gt;$$ \cos(a+b) = \cos a \cos b - \sin a \sin b$$&lt;/p&gt;
&lt;p&gt;we simplify the derivative equation:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\frac{d}{dx} \cos x &amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{\cos x \cos \Delta x - \sin x \sin \Delta x - \cos x}{\Delta x} \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \left[ \frac{\cos x \cos \Delta x - \cos x}{\Delta x} + \frac{-\sin x \sin\Delta x}{\Delta x}\right] \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \left[ \cos x \left( \frac{\cos \Delta x - 1}{\Delta x} \right) - \sin x \frac{\sin \Delta x}{\Delta x} \right] \\\&lt;br&gt;
&amp;amp;= \cos x \cdot 0 - \sin x \cdot 1 \\\&lt;br&gt;
&amp;amp;= -\sin x
\end{align}$$&lt;/p&gt;
&lt;p&gt;where in fourth equation, we have used the limits properties mentioned in the proof for $\sin x $ derivative.&lt;/p&gt;
&lt;h2 id=&#34;product-rule&#34;&gt;Product rule&lt;/h2&gt;
&lt;p&gt;The product rule tells us how to compute the derivative of the product of two functions:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$ (uv)^\prime = u^\prime v + uv^\prime $$
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;proof-3&#34;&gt;Proof&lt;/h3&gt;
&lt;p&gt;Using the formula for the derivative:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
(uv)^\prime &amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{(uv)(x + \Delta x) - (uv)(x)}{\Delta x} \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{u(x + \Delta x)v(x + \Delta x) - u(x)v(x)}{\Delta x} \\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Then, we add and subtract the term $u(x+\Delta x)v(x)$ to the derivative equation:
&lt;font size=&#34;2&#34;&gt;
$$\begin{align}
(uv)^\prime &amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{u(x + \Delta x)v(x + \Delta x) - u(x)v(x) + u(x + \Delta x)v(x) - u(x + \Delta x)v(x)}{\Delta x} \\\&lt;br&gt;
&amp;amp;= \lim_{\Delta x \rightarrow 0} \left[ \frac{u(x+\Delta x) - u(x)}{\Delta x} v(x) + u(x + \Delta x) \frac{v(x + \Delta x) - v(x)}{\Delta x} \right] \\\&lt;br&gt;
&amp;amp;= u^\prime v + u v^\prime
\end{align}$$
&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;Note that we have used the fact that $\lim_{\Delta x \rightarrow 0} u(x + \Delta x) = u(x)$, since $u$ is differentiable and therefore continuous.&lt;/p&gt;
&lt;h2 id=&#34;quotient-rule&#34;&gt;Quotient rule&lt;/h2&gt;
&lt;p&gt;The formula for differentiating quotients (or fractions) is:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$\left( \frac{u}{v} \right)^\prime = \frac{u^\prime v - uv^\prime}{v^2}$$
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;proof-4&#34;&gt;Proof&lt;/h3&gt;
&lt;p&gt;Again, starting from the main formula for a derivative, we have:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\left( \frac{u}{v} \right)^\prime &amp;amp;= \lim_{\Delta x \rightarrow 0} \frac{\frac{u(x + \Delta x)}{v(x + \Delta x)} - \frac{u(x)}{v(x)}}{\Delta x} \\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Let $\Delta u = u(x + \Delta x) - u(x)$ and $\Delta v = v(x + \Delta x) - v(x)$, then we simplify the numerator:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\frac{u(x + \Delta x)}{v(x + \Delta x)} - \frac{u(x)}{v(x)} &amp;amp;= \frac{u + \Delta u}{v + \Delta v} - \frac{u}{v} \\\&lt;br&gt;
&amp;amp;= \frac{(u + \Delta u)v - u(v + \Delta v)}{(v + \Delta v)v} \\\&lt;br&gt;
&amp;amp;= \frac{uv + (\Delta u)v - uv + u\Delta v}{(v + \Delta v)v} \\\&lt;br&gt;
&amp;amp;= \frac{(\Delta u)v - u(\Delta v)}{(v + \Delta v)v}
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now that we have simplified the numerator, we can use it to simplify the difference quotient:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\frac{\frac{u(x + \Delta x)}{v(x+\Delta x)} - \frac{u(x)}{v(x)}}{\Delta x} &amp;amp;= \frac{\frac{(\Delta u)v - u(\Delta v)}{(v + \Delta v)v}}{\Delta x} \\\&lt;br&gt;
&amp;amp;= \frac{1}{\Delta x} \frac{(\Delta u)v - u(\Delta v)}{(v + \Delta v)v} \\\&lt;br&gt;
&amp;amp;= \frac{\left( \frac{\Delta u}{\Delta x} \right) v - u \left( \frac{\Delta v}{\Delta x} \right)}{(v + \Delta v)v}
\end{align}$$&lt;/p&gt;
&lt;p&gt;since $v$ is differentiable (and therefore continuous), then $\lim_{x \rightarrow 0} v(x + \Delta x) = v(x)$, and we have that:&lt;/p&gt;
&lt;p&gt;$$
\lim_{\Delta x \rightarrow 0}  \frac{\left( \frac{\Delta u}{\Delta x} \right) v - u \left( \frac{\Delta v}{\Delta x} \right)}{(v + \Delta v)v} = \frac{v \frac{du}{dx} - u \frac{dv}{dx}}{v^2}
$$&lt;/p&gt;
&lt;h2 id=&#34;chain-rule&#34;&gt;Chain rule&lt;/h2&gt;
&lt;p&gt;The chain rule tells us how to find the derivative of a composition of functions like $(f \circ g)(x) = f(g(x))$. To find the derivative of $f$ with respect to $x$, we use the chain rule:&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    $$ \frac{df}{dx} = \frac{df}{dz}\frac{dz}{dx}$$
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;where we have set $z = g(x)$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigations of degradation and encapsulation of plastic scintillator</title>
      <link>https://dibgerge.github.io/publication/2019-nimpr/</link>
      <pubDate>Tue, 05 Feb 2019 19:34:55 -0500</pubDate>
      <guid>https://dibgerge.github.io/publication/2019-nimpr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>In-situ fatigue monitoring procedure using nonlinear ultrasonic surface waves considering the nonlinear effects in the measurement system</title>
      <link>https://dibgerge.github.io/publication/2019-net/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2019-net/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ultrasound Modeling and Simulation: Status Update</title>
      <link>https://dibgerge.github.io/publication/2018-pnnl/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2018-pnnl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>https://dibgerge.github.io/tutorial/mit1801/unit2/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/tutorial/mit1801/unit2/</guid>
      <description>&lt;p&gt;The applications of calculus&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neural Interactive Machine Learning</title>
      <link>https://dibgerge.github.io/project/niml/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/niml/</guid>
      <description>&lt;p&gt;Machine intelligence advances have elevated the potential of computer-based video analytics but machines alone still fall short of human visual recognition capabilities. Humans, however, cannot address the high volumes of data in need of analysis. Despite exponential growth in machine analytics, opportunities for improvement remain (reducing training sets, improving cross-platform compatibility, adapting to changing environments, etc.). This project aims at achieving higher performance thresholds by integrating the strengths of human and machine reasoning.&lt;/p&gt;
&lt;p&gt;We are currently building brain-computer interfaces and machine learning approaches to quantify neurological data reflecting fast visual recognition collected with an electroencephalogram (EEG) headset worn by a human participant viewing video data. The quality of psychological engagement are being investigated and the quality of EEG signatures are being evaluated based on reproducibility and accuracy.&lt;/p&gt;
&lt;p&gt;The NIML approach is envisaged to significantly enhance data processing with application to HIL processes that could benefit big data problems such as data labeling for medicine, social media, among others.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Validation of Ultrasound NDE Simulation Models</title>
      <link>https://dibgerge.github.io/project/ut-modeling/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/ut-modeling/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Nondestructive_testing&#34;&gt;Non-destructive evaluation and testing (NDE)&lt;/a&gt; is essential for ensuring the safety of operational nuclear power plants around the world. Ultrasonic testing is an NDE technique which is largely utilized for inspecting pipelines in the nuclear industry due to its ability to detect flaws hidden within the inner diameter of pipelines.&lt;/p&gt;
&lt;p&gt;Computer modeling and simulation is becoming an essential tool for transducer design and insight into ultrasonic nondestructive evaluation. For computational models to be of use in practical situations, it is important to develop techniques for inferring the reliability of inspections using simulated results. This includes information about the detectability of different defect types within different material varying in complexity and grain structure. To address this problem, we need to develop techniques to quantify confidence in simulations, and methods to incorporate experimental and structural noise into model outputs.&lt;/p&gt;
&lt;p&gt;In this project, we are building a large database of ultrasound inspection empirical data using different types of probes, materials, and defects. We are using this empirical data to: (1) Develop techniques for validating ultrasound inspection simulations; (2) Uncertainty quantification due to uncertain or unknown simulation input parameters; and (3) Develop noise models which can be fused with simulation data for analyzing inspection reliability using simulated data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ensembles of novelty detection classifiers for structural health monitoring using guided waves</title>
      <link>https://dibgerge.github.io/publication/2017-sms/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-sms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Challenges and Solutions in SHM for Nuclear Power Environments</title>
      <link>https://dibgerge.github.io/publication/2017-iwshm/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-iwshm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the usage of ultrasound computational models for decision making under ambiguity</title>
      <link>https://dibgerge.github.io/publication/2017-qnde/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Preliminary design of high temperature ultrasonic transducers for liquid sodium environments</title>
      <link>https://dibgerge.github.io/publication/2017b-qnde/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Integration and Assessment of Component Health Prognostics in Supervisory Control Systems</title>
      <link>https://dibgerge.github.io/publication/2017-npic/</link>
      <pubDate>Sun, 11 Jun 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-npic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Validation of Ultrasonic Nondestructive Examination (NDE) Computational Models – Phase 1</title>
      <link>https://dibgerge.github.io/publication/2017-pnnl/</link>
      <pubDate>Fri, 05 May 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-pnnl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Detecting Water in Dry Storage Canisters for Used Fuel</title>
      <link>https://dibgerge.github.io/publication/2017-ihlrwm/</link>
      <pubDate>Sun, 09 Apr 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-ihlrwm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PVT Degradation Studies: Acoustic Diagnostics</title>
      <link>https://dibgerge.github.io/publication/2017-osti/</link>
      <pubDate>Sat, 01 Apr 2017 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2017-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Learning and Statistical Signal Processing for Guided Wave Structural Health Monitoring</title>
      <link>https://dibgerge.github.io/project/gwshm/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/project/gwshm/</guid>
      <description>&lt;p&gt;Sparse ultrasonic guided waves sensor networks would increase safety and reduce maintenance costs of current civil and industrial structures by providing continuous information about structural health. Common damage modalities that are of concern include fatigue cracks and corrosion in metals, and delaminations and impact damage in composite materials. Ultrasonic guided wave testing is used in various industries due to its superior ability to rapidly inspect large areas in thin structures. Guided waves travel long distances and interrogate the entire thickness of a structure. These properties make guided waves of interest in structural health monitoring (SHM) since a small number of transducers is required to monitor a large structure.&lt;/p&gt;
&lt;p&gt;Due to the complexity of guided wave signals, detection strategies in guided wave SHM often are based on detecting changes in the signals based on reference signals collected when the structure is in its pristine state. Damage detection is challenging because there are multitude of other factors that affect the signal such as sensor aging, temperature changes, humidity, and/or varying loading conditions.&lt;/p&gt;
&lt;p&gt;In this project, we developed machine learning and statistical signal processing techniques for building reliable and efficient methods for damage classification in structures under varying environmental and operating conditions. In addition, we developed statistical methods for quantifying the probability of detection due to sensor aging and variations in environmental and operating condition.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Summary Describing Integration of ERM Methodology into Supervisory Control Framework with Software Package Documentation</title>
      <link>https://dibgerge.github.io/publication/2016-osti/</link>
      <pubDate>Tue, 20 Sep 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2016-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Experimental Design for Evaluating Selected Nondestructive Measurement Technologies</title>
      <link>https://dibgerge.github.io/publication/2016b-osti/</link>
      <pubDate>Sat, 16 Jul 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2016b-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ultrasound Sensors and Methods for Nuclear Power Plant Environments</title>
      <link>https://dibgerge.github.io/project/ut-sensors/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/ut-sensors/</guid>
      <description>&lt;center&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box fancy-figure caption-position-bottom caption-effect-fade&#34; style=&#34;max-width:400px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;featured.png&#34; alt=&#34;Schematic of nuclear power plant components which require monitoring using NDE techniques.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;featured.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Schematic of nuclear power plant components which require monitoring using NDE techniques.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;p&gt;This is a topic co project focuses on demonstration of ultrasound sensing technology and techniques for various applications related to nuclear power plant life cycle, next generation advanced reactors, and radiation monitoring at border portals. The focus of this research has been on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assessment of  conventional ultrasound and non-linear ultrasound non-destructive evaluation techniques capable of detecting impending damage before crack formation. This project focuses on creep and fatigue damage modalities in nuclear power plants.&lt;/li&gt;
&lt;li&gt;Development of high temperature ultrasound sensor probes, capable of withstanding temperatures up to 550 C for extended period of time. Also, the sensors are designed to be capable of reliable damage detection in sodium coolants.&lt;/li&gt;
&lt;li&gt;Assessment of ultrasound inspection reliability under challenging environments, and sensor calibration and methods for compensating sensor aging.&lt;/li&gt;
&lt;li&gt;Water detection in spent fuel dry cask storage canisters.&lt;/li&gt;
&lt;li&gt;Fog detection in PVT scintillators used at border portals for radiation detection. Fog build up in those plastic detectors reduce their sensitivity. We assessed ultrasound techniques for predicting fogging levels in the detectors.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Non-destructive Measurements for Diagnostics of Advanced Reactor Passive Components</title>
      <link>https://dibgerge.github.io/publication/2016-icapp/</link>
      <pubDate>Sun, 17 Apr 2016 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2016-icapp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Design and performance of optimal detectors for guided wave structural health monitoring</title>
      <link>https://dibgerge.github.io/publication/2016-shm/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2016-shm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Guided Wave Structural Health Monitoring for Impact Damage Detection and Characterization</title>
      <link>https://dibgerge.github.io/publication/2015-asc/</link>
      <pubDate>Thu, 01 Oct 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-asc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>State of the Art Assessment of NDE Techniques for Aging Cable Management in Nuclear Power Plants FY2015</title>
      <link>https://dibgerge.github.io/publication/2015-osti/</link>
      <pubDate>Tue, 08 Sep 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assessment of NDE for key indicators of aging cables in nuclear power plants – Interim status</title>
      <link>https://dibgerge.github.io/publication/2015b-qnde/</link>
      <pubDate>Mon, 20 Jul 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Experimental validation of ultrasonic NDE simulation software</title>
      <link>https://dibgerge.github.io/publication/2015-qnde/</link>
      <pubDate>Mon, 20 Jul 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Progress towards prognostic health management of passive components in advanced reactors: Model selection and evaluation</title>
      <link>https://dibgerge.github.io/publication/2015-phm/</link>
      <pubDate>Mon, 22 Jun 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-phm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Component-Level Prognostics Health Management Framework for Passive Components</title>
      <link>https://dibgerge.github.io/publication/2015b-osti/</link>
      <pubDate>Fri, 19 Jun 2015 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2015b-osti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Rotating field EC-GMR sensor for crack detection at fastener site in layered structures</title>
      <link>https://dibgerge.github.io/publication/2015-ieee-sensors/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2015-ieee-sensors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EC-GMR array with rotating current excitation for multilayered riveted structures inspection</title>
      <link>https://dibgerge.github.io/publication/2014-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feasibility of PZT ceramics for impact damage detection in composite structures</title>
      <link>https://dibgerge.github.io/publication/2014d-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014d-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image processing algorithms for automated analysis of GMR data from inspection of multilayer structures</title>
      <link>https://dibgerge.github.io/publication/2014c-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014c-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multitechnique monitoring of fatigue damage in adhesively bonded composite lap-joints</title>
      <link>https://dibgerge.github.io/publication/2014b-qnde/</link>
      <pubDate>Sun, 20 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2014b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Giant Magnetoresistance Sensors for Aircraft Inspection</title>
      <link>https://dibgerge.github.io/project/gmr/</link>
      <pubDate>Tue, 01 Jul 2014 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/gmr/</guid>
      <description>&lt;p&gt;Nondestructive inspection of multi-layered airframe geometries is a significant challenge largely due to complexity of test geometry and deep lying defects. Structural geometry of interest includes different configurations of aircraft skins, stringers, doublers, wing-splice with fasteners and deep lying cracks and corrosion. Inspection of these complex geometries requires dealing with a large number of variables which affect damage detection performance (material, size, thickness, edges, air gaps, etc.), experimental sensor system (frequency, waveform shape, harmonics, sampling intervals, circuit design etc.), and defect variables (length, width, volume, shape, distribution, orientation, etc.). Combination of these classes of variables encountered in any inspection makes the interpretation of the signals very challenging.&lt;/p&gt;
&lt;p&gt;The purpose of this project was to design, fabricate and test a novel transducer and inspection technique for detecting cracks near fastener sites in aircrafts with high efficiency and sensitivity. The transducer uses Giant Megnetoresistance (GMR) sensor arrays for increasing sensitivity and reducing required aircraft scan times. Also, a rotating coil excitation is used, which allows the probe to be uniformly sensitive to cracks oriented in arbitrary direction. This is a significant advancement over the previous state-of-the-art, where probes were only sensitive to cracks oriented parallel to the direction of coil current flow. A finite element model (FEM) was also developed for simulating the designed probes. FEM simulations were then used for optimizing the probe design, including GMR sensor placement, excitation coil parameters, and signal processing methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Advanced Signal Processing Algorithms in Structural Integrity Monitoring</title>
      <link>https://dibgerge.github.io/publication/2014-icons/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 -0800</pubDate>
      <guid>https://dibgerge.github.io/publication/2014-icons/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Wireless Sensor Node for Structural Health Monitoring using Guided Wave Testing</title>
      <link>https://dibgerge.github.io/publication/2013-me/</link>
      <pubDate>Tue, 01 Oct 2013 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2013-me/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Novel Mode Decomposition Algorithms for Lamb Wave Signal Analysis in Online Monitoring of Structures</title>
      <link>https://dibgerge.github.io/publication/2013-ejam/</link>
      <pubDate>Thu, 14 Mar 2013 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2013-ejam/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sensor-tilt invariance analysis for eddy current signals</title>
      <link>https://dibgerge.github.io/publication/2012-ndte/</link>
      <pubDate>Thu, 01 Nov 2012 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2012-ndte/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pre-processing methods for eddy current data analysis using Hilbert-Huang Transform</title>
      <link>https://dibgerge.github.io/publication/2011-isaem/</link>
      <pubDate>Wed, 05 Sep 2012 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2011-isaem/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eddy Current Inspection Autoanalysis of Steam Generator Tubes in Nuclear Power Plants</title>
      <link>https://dibgerge.github.io/project/autoanalysis/</link>
      <pubDate>Fri, 01 Jun 2012 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/autoanalysis/</guid>
      <description>&lt;center&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box fancy-figure caption-position-bottom caption-effect-fade&#34; style=&#34;max-width:400px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;featured.png&#34; alt=&#34;Processing pipeline for autoanalysis software.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;featured.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Processing pipeline for autoanalysis software.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/center&gt;
&lt;p&gt;Steam generators (SG) are heat exchanger units used in nuclear power plants. Each SG unit typically contains 10000 - 20000 tubes which are exposed to harsh environmental conditions such as high temperatures, high pressures, high fluid flow rates and material interactions resulting in various types of tube degradations - mechanical wear, stress corrosion cracking (SCC), pitting, volumetric degradation, inter granular attack (IGA), loose parts and denting. Electromagnetic methods at low frequencies such as eddy current (EC) have been widely used for inspecting SG tubes. Generally, trained experts will analyze the acquired data looking for any damage indication. However, due to the large volume of data, manual inspection is highly susceptible for a person to miss an indication of damage in the data. The goal of this project is to automate damage detection and classification for eddy current inspection of steam generator tubes in nuclear power plants.&lt;/p&gt;
&lt;p&gt;The automated signal analysis system pipeline involves 1) pre-processing and region of interest (ROI) detection, 2) feature extraction and 3) classification. We used physics based feature extraction and machine learning techniques to automate and enhance the current state-of-the-art performance of manual signal analysis. We tested the pipelines using data from a performance demonstration database consisting of on-site inspection data obtained from multiple nuclear power plants in the USA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>High performance wireless sensors system for structural health monitoring</title>
      <link>https://dibgerge.github.io/publication/2011-qnde/</link>
      <pubDate>Fri, 22 Jul 2011 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2011-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nonlinear, non-stationary image processing technique for eddy current NDE</title>
      <link>https://dibgerge.github.io/publication/2011b-qnde/</link>
      <pubDate>Fri, 22 Jul 2011 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2011b-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wireless NDE sensor system for continuous monitoring</title>
      <link>https://dibgerge.github.io/publication/2010-qnde/</link>
      <pubDate>Thu, 22 Jul 2010 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/publication/2010-qnde/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Wireless Senor Networks for Structural Health Monitoring</title>
      <link>https://dibgerge.github.io/project/wsn/</link>
      <pubDate>Tue, 27 Apr 2010 00:00:00 -0700</pubDate>
      <guid>https://dibgerge.github.io/project/wsn/</guid>
      <description>&lt;div style=&#34;text-align: center;&#34;&gt;

&lt;link rel=&#34;stylesheet&#34; href=&#34;https://dibgerge.github.io/css/hugo-easy-gallery.css&#34; /&gt;
&lt;div class=&#34;box fancy-figure caption-position-bottom caption-effect-fade&#34; style=&#34;max-width:400px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;featured.jpg&#34; alt=&#34;Schematic of sensor network with centralized architecture.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;featured.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Schematic of sensor network with centralized architecture.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;The use of wireless sensor networks in structural health monitoring can significantly increase safety and reduce manufacturing and maintenance costs. In this project, we integrate guided wave sensors with wireless sensor modules for continuous monitoring of civil structures. The wireless sensors eliminate the need for cables, reducing overall structure weight (especially important in aerospace industry) and single points of failure. We designed sensor interface boards for the Iris wireless nodes allowing transmitting and receiving guided waves using piezoelectric sensors. A distributed control algorithm is also implemented for controlling a wireless sensor network from a base station.



&lt;div class=&#34;gallery caption-position-center caption-effect-fade hover-effect-zoom hover-transition&#34; itemscope itemtype=&#34;http://schema.org/ImageGallery&#34;&gt;
	  
  

&lt;div class=&#34;box&#34; style=&#34;max-width:300px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://dibgerge.github.io/project/wsn/wsn_board.png&#39;);&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;project/wsn/wsn_board.png&#34; alt=&#34;Sensor interface circuit board for guided wave reception.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;wsn_board.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Sensor interface circuit board for guided wave reception.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

  

&lt;div class=&#34;box&#34; style=&#34;max-width:300px&#34;&gt;
  &lt;figure  itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://dibgerge.github.io/project/wsn/wsn_demo.jpg&#39;);&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;project/wsn/wsn_demo.jpg&#34; alt=&#34;Two sensor nodes configured for in transmit-receive mode.&#34;/&gt;
    &lt;/div&gt;
    &lt;a href=&#34;wsn_demo.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
      &lt;figcaption&gt;
          &lt;p&gt;Two sensor nodes configured for in transmit-receive mode.&lt;/p&gt;
      &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
