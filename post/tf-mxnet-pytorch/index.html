<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Gerges Dib">

  
  
  
    
  
  <meta name="description" content="Comparison of three deep learning frameworks.">

  
  <link rel="alternate" hreflang="en-us" href="https://dibgerge.github.io/post/tf-mxnet-pytorch/">

  


  
  
  
  <meta name="theme-color" content="#ba68c8">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/atom-one-light.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/atom-one-light.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-104457229-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           document.location = url;
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target);  
  }

  gtag('js', new Date());
  gtag('config', 'UA-104457229-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hufb0bba0b24038dd6774d907c032416d0_44829_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hufb0bba0b24038dd6774d907c032416d0_44829_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://dibgerge.github.io/post/tf-mxnet-pytorch/">

  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Ge[o]rges Dib">
  <meta property="og:url" content="https://dibgerge.github.io/post/tf-mxnet-pytorch/">
  <meta property="og:title" content="Tensorflow, PyTorch, and MxNet | Ge[o]rges Dib">
  <meta property="og:description" content="Comparison of three deep learning frameworks."><meta property="og:image" content="https://dibgerge.github.io/post/tf-mxnet-pytorch/featured.png">
  <meta property="twitter:image" content="https://dibgerge.github.io/post/tf-mxnet-pytorch/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-03-11T00:00:00-07:00">
    
    <meta property="article:modified_time" content="2019-03-11T00:00:00-07:00">
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://dibgerge.github.io/post/tf-mxnet-pytorch/"
  },
  "headline": "Tensorflow, PyTorch, and MxNet",
  
  "image": [
    "https://dibgerge.github.io/post/tf-mxnet-pytorch/featured.png"
  ],
  
  "datePublished": "2019-03-11T00:00:00-07:00",
  "dateModified": "2019-03-11T00:00:00-07:00",
  
  "author": {
    "@type": "Person",
    "name": "Gerges Dib"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Ge[o]rges Dib",
    "logo": {
      "@type": "ImageObject",
      "url": "img/https://dibgerge.github.io/"
    }
  },
  "description": "Comparison of three deep learning frameworks."
}
</script>

  

  


  


  





  <title>Tensorflow, PyTorch, and MxNet | Ge[o]rges Dib</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="dark">

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>#Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>#Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/post/"><span>Blog</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      

      

    </ul>

  </div>
</nav>


  <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Tensorflow, PyTorch, and MxNet</h1>

  
  <p class="page-subtitle">An experimental and subjective comparison</p>
  

  


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Gerges Dib</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Mar 11, 2019
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  
  <span class="middot-divider"></span>
  <a href="/post/tf-mxnet-pytorch/#disqus_thread"></a>
  

  
  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 720px;">
  <div style="position: relative">
    <img src="/post/tf-mxnet-pytorch/featured_hu07e0a86415001b8c78f9e359c8760da8_307568_720x0_resize_lanczos_2.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>In the past 2 years, I have been exclusively using Tensorflow with Keras for training and testing deep neural networks. I never really thought twice about it, because this is what everyone else seems to be using. I mean, just looking at the popularity of those frameworks in github compared with their closest competitors was enough to make the decision for me. Here are the approximate statistics as of March 2019 for the four most popular frameworks.</p>
<table>
<thead>
<tr>
<th></th>
<th><a href="https://github.com/tensorflow/tensorflow">Tensorflow</a></th>
<th><a href="https://github.com/keras-team/keras">Keras</a></th>
<th><a href="https://github.com/pytorch/pytorch">Pytorch</a></th>
<th><a href="https://github.com/apache/incubator-mxnet">Mxnet</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Github <i class="fas fa-star"></i></td>
<td>122,500</td>
<td>39,000</td>
<td>25,500</td>
<td>16,500</td>
</tr>
</tbody>
</table>
<p>Recently, I have been going through the lectures of <a href="fast.ai">Jeremy Howard's Fast.ai</a> excellent class, where they use Pytorch as the backend of the high-level library they built. This was one of the reasons I started questioning what was I missing by limiting myself to Tensorflow. Also, I have seen the extensive vision library of <a href="https://gluon-cv.mxnet.io/index.html">MxNet's GluonCV</a>, and this really made me feel that I might be missing out.</p>
<p>In addition to all the fear of missing out stuff, I was coding my own implementation of <a href="https://gluon-cv.mxnet.io/index.html">ResNet</a>, and I scoured online the plethora of different implementations of ResNet, some with lots of <i class="fas fa-star">s</i>. I realized that many had implementation details which differed from the original paper, and it was not clear if it is intentional or not. Thus I really though that a test in reproducibility is due and so I did.</p>
<p>I set out to compare the three frameworks: tensorflow, pytorch, and mxnet. I wanted to use some of the built-in convolutional neural networks with built-in pre-trained weights to directly classify Imagenet's validation dataset images. Throughout this comparison, I was looking for three factors:</p>
<ol>
<li>Ease of loading the dataset and reproducing the pre-processing steps required before feeding images to the neural network for classification.</li>
<li>Computed error rate vs framework's reported error. It would be also nice to compare the results with the original publication, but most report validation error using 10-crops, and here we use only single crop.</li>
<li>Inference speed.</li>
</ol>
<h2 id="dataset-and-convolutional-neural-network-architectures">Dataset and Convolutional Neural Network Architectures</h2>
<p>The datatset I used was Imagenet's validation dataset which constitutes of 50,000 images with different sizes. The easiest way to get your hands on the data is to download it from Kaggle <a href="https://www.kaggle.com/c/imagenet-object-localization-challenge">here</a>.</p>
<p>For the frameworks, I used the following versions:</p>
<ul>
<li><strong>Tensorflow 1.13</strong> with Keras as the front-end interface (Note this is different from using Keras with Tensorflow backend since now Tensorflow comes packed with its own Keras version, which is not compatible with other frameworks).</li>
<li><strong>PyTorch 1.0.1</strong> with PyTorch vision for convolutional neural networks implementations</li>
<li><strong>MxNet 1.4</strong> with GluonCV for convolutional neural networks implementaitons</li>
</ul>
<p>For the convolutional neural network, I considered four different architectures: <a href="https://arxiv.org/abs/1512.03385">ResNet50</a>, <a href="https://arxiv.org/abs/1512.03385">Resnet101</a>, <a href="https://arxiv.org/abs/1704.04861">Mobilenet</a>, and <a href="https://arxiv.org/abs/1608.06993">Densenet121</a>.</p>
<p>The top 1 error published on each frameworks&rsquo; website, based on a single center crop evaluation is as follows:</p>
<table>
<thead>
<tr>
<th></th>
<th><a href="https://github.com/keras-team/keras-applications">Tensorflow (Keras)</a></th>
<th><a href="https://pytorch.org/docs/stable/torchvision/models.html">Pytorch</a></th>
<th><a href="https://gluon-cv.mxnet.io/model_zoo/classification.html">Mxnet (GluonCV)</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Resnet50</td>
<td>25.10</td>
<td>23.85</td>
<td>22.64</td>
</tr>
<tr>
<td>Resnet101</td>
<td>23.60</td>
<td>22.63</td>
<td>21.66</td>
</tr>
<tr>
<td>Mobilenet</td>
<td>29.60</td>
<td>N/A</td>
<td>26.72</td>
</tr>
<tr>
<td>Densenet121</td>
<td>25.0</td>
<td>25.35</td>
<td>25.03</td>
</tr>
</tbody>
</table>
<p>We note here that the error for Resnet101 is reported in Keras Applications, but Resnet101 is not packaged with Tensorflow 1.13, which is used in this experiment, and thus we won't have any results for it. Also, Pytorch does not come packaged with an implementation of Mobilenet.</p>
<p>Also, it is interesting to see that especially for Resnet implementations, it is obvious that the accuracy of Mxnet &gt; PyTorch &gt; Tensorflow.</p>
<h2 id="experiments">Experiments</h2>
<p>All the code used here can be found on <a href="https://github.com/dibgerge/blog-tf-mxnet-pytorch">github</a>. The biggest challenge here really is loading and pre-processing the images the right way. The following briefly describes how I did it for each of the three frameworks.</p>
<h3 id="tensorflow-pre-processing">Tensorflow pre-processing</h3>
<p>Uses the <code>Sequence</code> abstract class for loading the data using a a generator. The pre-processing pipeline is as follows:</p>
<ol>
<li>Resized the shorter side of the image to 256 pixels (implemented manually).</li>
<li>Center cropped the image to 224 x 224 pixels (implemented manually).</li>
<li>Apply the function <code>preprocess_input</code> which applies the appropriate normalization based on how the network is trained. This function is provided with each different architecture built-in Tensorflow's Keras frontend.</li>
</ol>
<h3 id="pytorch-pre-processing">Pytorch pre-processing</h3>
<p>Used the <code>Dataset</code> and <code>Dataloader</code> interfaces to feed the data to the neural network. The standard pipeline for pre-processing images for all architectures is documented and is a composition of four transforms using Pytorch's <code>transforms</code> API:</p>
<ol>
<li>Resize image to 256 pixels (using <code>transforms.Resize</code>)</li>
<li>Center image to 224 pixels (using <code>transforms.CenterCrop</code>)</li>
<li>Convert images to pytorch tensor (using <code>transforms.ToTensor</code>)</li>
<li>Normalize image by mean subtraction and standard deviation scaling (using <code>transforms.Normalize</code>). The normalization values are given in the Pytorch's documentation.</li>
</ol>
<h3 id="mxnet-pre-processing">Mxnet pre-processing</h3>
<p>Used the <code>Dataset</code> and <code>Dataloader</code> interfaces to feed the data to the neural network. Mxnet comes packaged with a preset function which applies the required pipeline for models pre-trained on imagenet, using the <code>gluoncv.data.transforms.presets.imagenet.transform_eval</code> function.</p>
<h3 id="results">Results</h3>
<p>The following table summarizes the achieved error percentages for each of the four architectures using the three different frameworks.</p>
<table>
<thead>
<tr>
<th>(% error)</th>
<th>Tensorflow</th>
<th>Pytorch</th>
<th>Mxnet</th>
</tr>
</thead>
<tbody>
<tr>
<td>Resnet50</td>
<td>26.92</td>
<td>23.87</td>
<td>22.64</td>
</tr>
<tr>
<td>Resnet101</td>
<td>N/A</td>
<td>22.63</td>
<td>21.60</td>
</tr>
<tr>
<td>Mobilenet</td>
<td>29.91</td>
<td>N/A</td>
<td>26.73</td>
</tr>
<tr>
<td>Densenet121</td>
<td>26.69</td>
<td>25.57</td>
<td>25.10</td>
</tr>
</tbody>
</table>
<p>Interestingly, although I had the most experience with Keras, I could not reproduce the published results for Resnet and Densenet. This is probably because I had to manually implement the image resizing and cropping, which might be different one used to generate the published results. On the other hand, Pytorch provides the required documentation to be able to reproduce the results very closely. MxNet takes it even a step further by providing a single function which applies all required pre-processing, and the results match very well with published ones.</p>
<p>As for running times, I measured the total running time for classifying 50,000 images.  All predictions were made on GPU (Nvidia GTX 1080 Ti), while the image pre-processing was made on CPU. The following tables summarizes the running time results in seconds. <strong>Please take those results with a huge grain of salt, since times vary a lot when loading and reloading large data from disk</strong>:</p>
<table>
<thead>
<tr>
<th>(seconds)</th>
<th>Tensorflow</th>
<th>Pytorch</th>
<th>Mxnet</th>
</tr>
</thead>
<tbody>
<tr>
<td>Resnet50</td>
<td>137</td>
<td>119</td>
<td>140</td>
</tr>
<tr>
<td>Resnet101</td>
<td>N/A</td>
<td>159</td>
<td>214</td>
</tr>
<tr>
<td>Mobilenet</td>
<td>82</td>
<td>N/A</td>
<td>118</td>
</tr>
<tr>
<td>Densenet121</td>
<td>173</td>
<td>120</td>
<td>195</td>
</tr>
</tbody>
</table>
<p>First, those results are somehow unfair to tensorflow. This is because I used threading with 4 workers for pre-processing images in Tensorflow, while 4 workers with multiprocessing was used for MxNet and Pytorch. But, this is rather Tensorflow/keras fault due to a <a href="https://github.com/keras-team/keras/issues/10855">bug</a> not allowing me to use multiprocessing. Also, for Mxnet and Pytorch I measured the average time it took to classify 10 images (the batch size used). I did not do this in Tensorflow, because there is no easy way to measure per-batch times.</p>
<table>
<thead>
<tr>
<th>(milliseconds)</th>
<th>Tensorflow*</th>
<th>Pytorch</th>
<th>Mxnet</th>
</tr>
</thead>
<tbody>
<tr>
<td>Resnet50</td>
<td>N/A</td>
<td>6.7 $\pm$ 4.3</td>
<td>12.1 $\pm$ 1.9</td>
</tr>
<tr>
<td>Resnet101</td>
<td>N/A</td>
<td>11.8 $\pm$ 1.2</td>
<td>21.0 $\pm$ 3.2</td>
</tr>
<tr>
<td>Mobilenet</td>
<td>N/A</td>
<td>N/A</td>
<td>6.7 $\pm$ 1.5</td>
</tr>
<tr>
<td>Densenet121</td>
<td>N/A</td>
<td>15.6 $\pm$ 1.7</td>
<td>26.7 $\pm$ 3.7</td>
</tr>
</tbody>
</table>
<p>Most of the time here is being spent loading the data from disk, and the GPU is not fully utilized. For example, based on average inference of 10 images in Resnet50, it takes about 33.5 seconds to classify all 50,000 images using PyTorch and about 60.5 seconds using Mxnet. We can reduce total inference by more than half if the GPU is kept busy.
Thus, the importance of handling data appropriately if speed matters.</p>
<h2 id="who-is-the-winner">Who is the winner?</h2>
<p>I think this experiment allowed me to assess three things:</p>
<ul>
<li>
<p><strong>Availability of pre-trained networks</strong>: trophy goes to <em>Mxnet</em>. The extensive vision library of architectures/preset image processing is very impressive. Jury still out on other domains (RL, NLP). Tensorflow is a second, and Pytorch did not have much architecture packaged with it.</p>
</li>
<li>
<p><strong>Reproducibility</strong>: Again, trophy to <em>Mxnet</em>, with PyTorch a close second. I could not reproduce Tensorflow's results, and it is not clear how to do it using the documentation.</p>
</li>
<li>
<p><strong>Data preparation</strong>: a tie with <em>Mxnet and Pytorch</em>. Both frameworks use very similar <code>Dataset</code> and <code>Dataloader</code> interfaces. I was able to get going using this interface very fast. Keras also has a very similar interface using <code>Sequence</code> class, but the absence of something similar to <code>Dataloader</code> results in having to return batches rather than simply one image at a time. Also Tensorflow has a <code>Dataset</code> interface which I used before but somehow made me feel I am programming in C all over again.</p>
</li>
<li>
<p><strong>Speed</strong>: <em>Pytorch</em>. It is very obvious that Pytorch won the speed race all over the board. Also, although there is no information for only inference time in Tensorflow, it looks like Tensorflow also has the edge on Mxnet.</p>
</li>
</ul>
<p>After this quick experiment, I am really excited about working with Mxnet and see how it goes. It looks like a great choice for working with computer vision, even though those experiments show it is the slowest. I am excited to see if it is really worth ditching Tensorflow for it, as I test it for different deep learning applications.</p>
<p><a class="fab fa-github-square" href="https://github.com/dibgerge/blog-tf-mxnet-pytorch">Get the code!</a></p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/deep-learning/">deep learning</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://dibgerge.github.io/post/tf-mxnet-pytorch/&amp;text=Tensorflow,%20PyTorch,%20and%20MxNet" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://dibgerge.github.io/post/tf-mxnet-pytorch/&amp;t=Tensorflow,%20PyTorch,%20and%20MxNet" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Tensorflow,%20PyTorch,%20and%20MxNet&amp;body=https://dibgerge.github.io/post/tf-mxnet-pytorch/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://dibgerge.github.io/post/tf-mxnet-pytorch/&amp;title=Tensorflow,%20PyTorch,%20and%20MxNet" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Tensorflow,%20PyTorch,%20and%20MxNet%20https://dibgerge.github.io/post/tf-mxnet-pytorch/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://dibgerge.github.io/post/tf-mxnet-pytorch/&amp;title=Tensorflow,%20PyTorch,%20and%20MxNet" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  
    
  
  






  
  
  
    
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hue3d0cc1f4f80b5dad2186a4a7c6ec73f_76029_250x250_fill_lanczos_center_2.png" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://dibgerge.github.io/">Gerges Dib</a></h5>
      <h6 class="card-subtitle">Applied Scientist</h6>
      <p class="card-text">Develop machine learning solutions</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/dibgerge" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/gergesdib/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=plh4vcMAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://stackoverflow.com/users/5495304/gerges-dib" target="_blank" rel="noopener">
        <i class="fab fa-stack-overflow"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/files/cv_gerges.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>




<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "dibgerge" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>






  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/project/niml/">Neural Interactive Machine Learning</a></li>
      
    </ul>
  </div>
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    <script id="dsq-count-scr" src="https://dibgerge.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.a0d331bcd05dbe8b31e244f796710f08.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
